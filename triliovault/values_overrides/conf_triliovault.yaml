conf:
  triliovault:
    ## Valid values are "nfs" and "s3"
    backup_target_type: "nfs"
    nfs:
      nfs_shares:
        - /opt/share1:
            192.168.122.101:
              node_selector: kubernetes_node_label1
            192.168.122.102:
              node_selector: kubernetes_node_label2
        - /opt/share2:
            192.168.122.201:
              node_selector: kubernetes_node_label1
            192.168.122.202:
              node_selector: kubernetes_node_label2
      nfs_options: "nolock,soft,vers=3,timeo=180,intr,lookupcache=none"
    s3:
      access_key: ''
      secret_key: ''
      ## S3 region, if your s3 does not have any region, just keep the parameter as it is
      region_name: ''
      bucket: ''
      endpoint_url: ''
      signature_version: 'default'
      auth_version: 'DEFAULT'
      ## If S3 backend is not Amazon S3 and SSL is enabled on S3 endpoint url then change it to 'True', otherwise keep it as 'False'
      ssl_enabled: False
      ## Provide s3 cert file content as multiline string
      s3_cert: |
        ""

    ## Configure 'dmapi_workers' parameter of '/etc/dmapi/dmapi.conf' file
    ## This parameter value used to spawn the number of dmapi processes to handle the incoming api requests.
    ## If your dmapi node has ‘n' cpu cores, It is recommended, to set this parameter to '4*n’.
    ## If dmapi_workers field is not present in config file. The Default value will be equals to number of cores present on the node
    datamover_api_workers: 16
  wlm: 
    trustee_role: creater
    triliovault_hostnames: ""
    ## Cloud admin domain id
    cloud_admin_domain: ""
    cloud_admin_project_id: ""
    cloud_admin_role: ""
    cloud_admin_user_id: ""
    ## Cloud admin domain id
    domain_name: ""
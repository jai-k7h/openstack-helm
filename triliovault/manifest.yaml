REVISION: 1
RELEASED: Mon Apr 25 11:26:26 2022
CHART: triliovault-0.1.0
USER-SUPPLIED VALUES:
conf:
  datamover:
    oslo_messaging_rabbit:
      ssl: true
      ssl_ca_file: /etc/rabbitmq/certs/ca.crt
      ssl_cert_file: /etc/rabbitmq/certs/tls.crt
      ssl_key_file: /etc/rabbitmq/certs/tls.key
  datamover_api:
    keystone_authtoken:
      cafile: /etc/triliovault/certs/ca.crt
  wlm:
    keystone_authtoken:
      cafile: /etc/triliovault/certs/ca.crt
endpoints:
  datamover:
    host_fqdn_override:
      default:
        tls:
          issuerRef:
            kind: ClusterIssuer
            name: ca-issuer
          secretName: triliovault-datamover-tls-api
    port:
      api:
        public: 443
    scheme:
      default: https
  identity:
    auth:
      admin:
        cacert: /etc/ssl/certs/openstack-helm.crt
      test:
        cacert: /etc/ssl/certs/openstack-helm.crt
      triliovault_datamover:
        cacert: /etc/ssl/certs/openstack-helm.crt
      triliovault_wlm:
        cacert: /etc/ssl/certs/openstack-helm.crt
    port:
      api:
        default: 443
    scheme:
      default: https
  ingress:
    port:
      ingress:
        default: 443
  oslo_messaging:
    port:
      https:
        default: 15680
  workloads:
    host_fqdn_override:
      default:
        tls:
          issuerRef:
            kind: ClusterIssuer
            name: ca-issuer
          secretName: triliovault-wlm-tls-api
    port:
      api:
        public: 443
    scheme:
      default: https
manifests:
  certificates: true
network:
  api:
    ingress:
      annotations:
        nginx.ingress.kubernetes.io/backend-protocol: https
pod:
  security_context:
    triliovault:
      container:
        triliovault_datamover_api:
          readOnlyRootFilesystem: false
          runAsUser: 0

COMPUTED VALUES:
bootstrap:
  enabled: false
  ks_user: triliovault
  script: |
    openstack token issue
conf:
  datamover:
    DEFAULT:
      debug: false
      log_config_append: /etc/triliovault-datamover/logging.conf
      max_commit_pending: 3
      max_uploads_pending: 3
      vault_data_directory: /var/trilio/triliovault-mounts
      vault_data_directory_old: /var/triliovault
      vault_s3_auth_version: DEFAULT
      vault_s3_ssl_cert: /etc/triliovault-datamover/s3-cert.pem
      verbose: true
    ceph:
      keyring_ext: .cinder.keyring
    cinder:
      http_retries: 10
    conductor:
      use_local: true
    contego_sys_admin:
      helper_command: sudo /usr/bin/privsep-helper
    dmapi_database:
      connection_recycle_time: 300
      max_overflow: 30
      max_pool_size: 10
      max_retries: -1
    libvirt:
      images_rbd_ceph_conf: /etc/ceph/ceph.conf
      rbd_user: cinder
    oslo_messaging_rabbit:
      ssl: true
      ssl_ca_file: /etc/rabbitmq/certs/ca.crt
      ssl_cert_file: /etc/rabbitmq/certs/tls.crt
      ssl_key_file: /etc/rabbitmq/certs/tls.key
    s3fuse_sys_admin:
      helper_command: sudo /usr/bin/privsep-helper
  datamover_api:
    DEFAULT:
      bindir: /usr/bin
      debug: false
      dmapi_enabled_apis: dmapi
      dmapi_enabled_ssl_apis: ""
      dmapi_listen_port: 8784
      instance_name_template: instance-%08x
      log_config_append: /etc/triliovault-datamover/logging.conf
      rootwrap_config: /etc/triliovault-datamover/rootwrap.conf
    database:
      connection_recycle_time: 300
      max_overflow: 30
      max_pool_size: 10
      max_retries: -1
    keystone_authtoken:
      auth_type: password
      cafile: /etc/triliovault/certs/ca.crt
      insecure: true
      memcache_security_strategy: ENCRYPT
      project_name: service
      signing_dir: /var/cache/dmapi
    oslo_messaging_notifications:
      driver: messagingv2
      topics: notifications,stacklight_notifications
    oslo_messaging_rabbit:
      rabbit_qos_prefetch_count: 64
    oslo_middleware:
      enable_proxy_headers_parsing: true
    wsgi:
      api_paste_config: /etc/triliovault-datamover/api-paste.ini
      ssl_cert_file: ""
      ssl_key_file: ""
  fuse: |
    # /etc/fuse.conf - Configuration file for Filesystem in Userspace (FUSE)

    # Set the maximum number of FUSE mounts allowed to non-root users.
    # The default is 1000.
    mount_max = 2000

    # Allow non-root users to specify the allow_other or allow_root mount options.
    user_allow_other
  logging:
    formatter_context:
      class: oslo_log.formatters.ContextFormatter
      datefmt: '%Y-%m-%d %H:%M:%S'
    formatter_default:
      datefmt: '%Y-%m-%d %H:%M:%S'
      format: '%(message)s'
    formatters:
      keys:
      - context
      - default
    handler_null:
      args: ()
      class: logging.NullHandler
      formatter: default
    handler_stderr:
      args: (sys.stderr,)
      class: StreamHandler
      formatter: context
    handler_stdout:
      args: (sys.stdout,)
      class: StreamHandler
      formatter: context
    handlers:
      keys:
      - stdout
      - stderr
      - "null"
    logger_amqp:
      handlers: ""
      level: WARNING
      qualname: amqp
    logger_amqplib:
      handlers: ""
      level: WARNING
      qualname: amqplib
    logger_boto:
      handlers: ""
      level: WARNING
      qualname: boto
    logger_datamover:
      handlers: ""
      level: INFO
      qualname: datamover
    logger_eventletwsgi:
      handlers: ""
      level: WARNING
      qualname: eventlet.wsgi.server
    logger_os.brick:
      handlers: ""
      level: INFO
      qualname: os.brick
    logger_root:
      handlers: stdout
      level: WARNING
    logger_sqlalchemy:
      handlers: ""
      level: WARNING
      qualname: sqlalchemy
    loggers:
      keys:
      - root
      - datamover
      - os.brick
  my_ip:
    host_interface: null
  policy: {}
  triliovault:
    backup_target_type: nfs
    cloud_admin_domain_name: ""
    cloud_admin_project_name: ""
    cloud_admin_user_name: ""
    datamover_api_workers: 16
    interface: internal
    nfs:
      nfs_options: nolock,soft,vers=3,timeo=180,intr,lookupcache=none
      nfs_shares:
      - ip: 192.168.122.101
        node_selector_key: openstack-compute-node
        node_selector_value: enabled
        path: /opt/share1
    s3:
      access_key: ""
      auth_version: DEFAULT
      bucket: ""
      endpoint_url: ""
      region_name: ""
      secret_key: ""
      signature_version: default
      ssl_enabled: false
    trustee_role: creater
  triliovault_object_store:
    DEFAULT:
      log_config_append: /etc/triliovault-object-store/logging.conf
      vault_s3_auth_version: DEFAULT
      vault_s3_ssl_cert: /etc/triliovault-wlm/s3-cert.pem
      vault_storage_nfs_export: TrilioVault
      vault_storage_type: s3
      verbose: true
    s3fuse_sys_admin:
      helper_command: sudo /usr/bin/workloadmgr-rootwrap /etc/triliovault/rootwrap.conf
        privsep-helper
  wlm:
    DEFAULT:
      api_paste_config: /etc/triliovault-wlm/api-paste.ini
      api_workers: 4
      cloud_admin_role: admin
      compute_driver: libvirt.LibvirtDriver
      config_status: configured
      debug: false
      domain_name: null
      glance_api_version: 2
      global_job_scheduler_override: false
      helper_command: sudo /usr/bin/workloadmgr-rootwrap /etc/triliovault/rootwrap.conf
        privsep-helper
      keystone_auth_version: 3
      log_config_append: /etc/triliovault-wlm/logging.conf
      max_wait_for_upload: 48
      neutron_api_insecure: false
      osapi_workloads_listen_port: 8781
      rootwrap_config: /etc/triliovault-wlm/rootwrap.conf
      state_path: /opt/stack/data/workloadmgr
      triliovault_hostnames: ""
      trustee_role: creater
      use_syslog: false
      vault_data_directory: /var/triliovault-mounts
      vault_data_directory_old: /var/triliovault
      vault_s3_auth_version: DEFAULT
      vault_s3_ssl_cert: /etc/triliovault/s3-cert.pem
      vault_storage_das_device: none
      verbose: true
      workloads_workers: 4
    alembic:
      script_location: /usr/share/workloadmgr/migrate_repo
      version_locations: /usr/share/workloadmgr/migrate_repo/versions
    clients:
      client_retry_limit: 3
      insecure: false
    filesearch:
      process_timeout: 300
    global_job_scheduler:
      misfire_grace_time: 600
    keystone_authtoken:
      admin_user: triliovault
      auth_plugin: password
      auth_type: password
      auth_version: v3
      cafile: /etc/triliovault/certs/ca.crt
      insecure: false
      service_token_roles_required: true
      signing_dir: /var/cache/workloadmgr
      username: triliovault
dependencies:
  dynamic:
    common:
      local_image_registry:
        jobs:
        - triliovault-image-repo-sync
        services:
        - endpoint: node
          service: local_image_registry
  static:
    api:
      jobs:
      - triliovault-db-sync
      - triliovault-ks-user
      - triliovault-ks-endpoints
      services:
      - endpoint: internal
        service: oslo_db
      - endpoint: internal
        service: identity
    contego:
      jobs:
      - triliovault-db-sync
      - triliovault-ks-user
      - triliovault-ks-endpoints
      services:
      - endpoint: internal
        service: oslo_db
      - endpoint: internal
        service: identity
    db_drop:
      services:
      - endpoint: internal
        service: oslo_db
    db_init:
      services:
      - endpoint: internal
        service: oslo_db
    db_sync:
      jobs:
      - tvault-db-init
      services:
      - endpoint: internal
        service: oslo_db
    image_repo_sync:
      services:
      - endpoint: internal
        service: local_image_registry
    ks_endpoints:
      jobs:
      - triliovault-ks-service
      services:
      - endpoint: internal
        service: identity
    ks_service:
      services:
      - endpoint: internal
        service: identity
    ks_user:
      services:
      - endpoint: internal
        service: identity
    rabbit_init:
      services:
      - endpoint: internal
        service: oslo_messaging
    tests:
      jobs:
      - triliovault-db-sync
      services:
      - endpoint: internal
        service: identity
      - endpoint: internal
        service: oslo_db
    wlm_api:
      jobs:
      - triliovault-db-sync
      - triliovault-ks-user
      - triliovault-ks-endpoints
      services:
      - endpoint: internal
        service: oslo_db
      - endpoint: internal
        service: identity
    wlm_cron:
      services:
      - endpoint: internal
        service: workloads
    wlm_scheduler:
      services:
      - endpoint: internal
        service: workloads
    wlm_workloads:
      services:
      - endpoint: internal
        service: workloads
endpoints:
  cluster_domain_suffix: cluster.local
  compute:
    host_fqdn_override:
      default: null
    hosts:
      default: nova-api
      public: nova
    name: nova
    path:
      default: /v2.1/%(tenant_id)s
    port:
      api:
        default: 8774
        public: 80
    scheme:
      default: http
  datamover:
    host_fqdn_override:
      default:
        tls:
          issuerRef:
            kind: ClusterIssuer
            name: ca-issuer
          secretName: triliovault-datamover-tls-api
    hosts:
      default: triliovault-datamover-api
      public: triliovault-datamover
    name: dmapi
    path:
      default: /v2
    port:
      api:
        default: 8784
        public: 443
    scheme:
      default: https
  identity:
    auth:
      admin:
        cacert: /etc/ssl/certs/openstack-helm.crt
        password: password
        project_domain_name: service
        project_name: service
        region_name: RegionOne
        user_domain_name: service
        username: admin
      test:
        cacert: /etc/ssl/certs/openstack-helm.crt
        password: password
        project_domain_name: service
        project_name: test
        region_name: RegionOne
        role: admin
        user_domain_name: service
        username: triliovault-test
      triliovault_datamover:
        cacert: /etc/ssl/certs/openstack-helm.crt
        password: password
        project_domain_name: service
        project_name: service
        region_name: RegionOne
        role: admin
        user_domain_name: service
        username: dmapi
      triliovault_wlm:
        cacert: /etc/ssl/certs/openstack-helm.crt
        password: password
        project_domain_name: service
        project_name: service
        region_name: RegionOne
        role: admin
        user_domain_name: service
        username: triliovault
    host_fqdn_override:
      default: null
    hosts:
      default: keystone
      internal: keystone-api
    name: keystone
    path:
      default: /v3
    port:
      api:
        default: 443
        internal: 5000
    scheme:
      default: https
  image:
    host_fqdn_override:
      default: null
    hosts:
      default: glance-api
      public: glance
    name: glance
    path:
      default: null
    port:
      api:
        default: 9292
        public: 80
    scheme:
      default: http
  ingress:
    port:
      ingress:
        default: 443
  local_image_registry:
    host_fqdn_override:
      default: null
    hosts:
      default: localhost
      internal: docker-registry
      node: localhost
    name: docker-registry
    namespace: docker-registry
    port:
      registry:
        node: 5000
  network:
    host_fqdn_override:
      default: null
    hosts:
      default: neutron-server
      public: neutron
    name: neutron
    path:
      default: null
    port:
      api:
        default: 9696
        public: 80
    scheme:
      default: http
  oslo_cache:
    auth:
      memcache_secret_key: null
    host_fqdn_override:
      default: null
    hosts:
      default: memcached
    port:
      memcache:
        default: 11211
  oslo_db_triliovault_datamover:
    auth:
      admin:
        password: password
        secret:
          tls:
            internal: mariadb-tls-direct
        username: root
      triliovault_datamover:
        password: password
        username: dmapi
    host_fqdn_override:
      default: null
    hosts:
      default: mariadb
    path: /dmapi
    port:
      mysql:
        default: 3306
    scheme: mysql+pymysql
  oslo_db_triliovault_wlm:
    auth:
      admin:
        password: password
        secret:
          tls:
            internal: mariadb-tls-direct
        username: root
      triliovault_wlm:
        password: password
        username: workloadmgr
    host_fqdn_override:
      default: null
    hosts:
      default: mariadb
    path: /workloadmgr
    port:
      mysql:
        default: 3306
    scheme: mysql+pymysql
  oslo_messaging:
    auth:
      admin:
        password: password
        secret:
          tls:
            internal: rabbitmq-tls-direct
        username: rabbitmq
      triliovault_wlm:
        password: password
        username: triliovault
    host_fqdn_override:
      default: null
    hosts:
      default: rabbitmq
    path: /triliovault
    port:
      amqp:
        default: 5672
      http:
        default: 15672
      https:
        default: 15680
    scheme: rabbit
    statefulset:
      name: rabbitmq-rabbitmq
      replicas: 2
  oslo_messaging_nova:
    auth:
      admin:
        password: password
        secret:
          tls:
            internal: rabbitmq-tls-direct
        username: rabbitmq
      nova:
        password: password
        username: nova
    host_fqdn_override:
      default: null
    hosts:
      default: rabbitmq
    path: /nova
    port:
      amqp:
        default: 5672
      http:
        default: 15672
    scheme: rabbit
    statefulset:
      name: rabbitmq-rabbitmq
      replicas: 2
  volumev3:
    host_fqdn_override:
      default: null
    hosts:
      default: cinder-api
      public: cinder
    name: cinder
    path:
      default: /v3/%(tenant_id)s
    port:
      api:
        default: 8776
        public: 80
    scheme:
      default: http
  workloads:
    host_fqdn_override:
      default:
        tls:
          issuerRef:
            kind: ClusterIssuer
            name: ca-issuer
          secretName: triliovault-wlm-tls-api
    hosts:
      default: triliovault-wlm-api
      public: triliovault-wlm
    name: workloadmgr
    path:
      default: /v1/$(tenant_id)s
    port:
      api:
        default: 8780
        public: 443
    scheme:
      default: https
helm-toolkit:
  global: {}
helm3_hook: true
images:
  local_registry:
    active: false
    exclude:
    - dep_check
    - image_repo_sync
  pull_policy: IfNotPresent
  tags:
    bootstrap: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
    db_drop: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
    db_init: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
    dep_check: quay.io/airshipit/kubernetes-entrypoint:v1.0.0
    image_repo_sync: docker.io/docker:17.07.0
    ks_endpoints: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
    ks_service: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
    ks_user: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
    rabbit_init: docker.io/rabbitmq:3.7-management
    triliovault_datamover: docker.io/trilio/triliovault-datamover-helm:5.0.0-train-ubuntu_bionic
    triliovault_datamover_api: docker.io/trilio/triliovault-datamover-api-helm:5.0.0-train-ubuntu_bionic
    triliovault_datamover_db_sync: docker.io/trilio/triliovault-datamover-api-helm:5.0.0-train-ubuntu_bionic
    triliovault_horizon: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
    triliovault_wlm_api: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
    triliovault_wlm_cloud_trust: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
    triliovault_wlm_cron: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
    triliovault_wlm_db_sync: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
    triliovault_wlm_scheduler: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
    triliovault_wlm_workloads: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
labels:
  datamover:
    node_selector_key: openstack-compute-node
    node_selector_value: enabled
  datamover_api:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  job:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  test:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  wlm_api:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  wlm_cron:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  wlm_scheduler:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
  wlm_workloads:
    node_selector_key: openstack-control-plane
    node_selector_value: enabled
manifests:
  certificates: true
  daemonset_datamover: true
  datamover_configmap_bin: true
  datamover_configmap_etc: true
  deployment_datamover_api: true
  deployment_wlm_api: true
  deployment_wlm_cron: true
  deployment_wlm_scheduler: true
  deployment_wlm_workloads: true
  ingress_api: true
  ingress_datamover_api: true
  ingress_wlm_api: true
  job_bootstrap: true
  job_datamover_db_drop: false
  job_datamover_db_init: true
  job_datamover_db_sync: true
  job_datamover_ks_endpoints: true
  job_datamover_ks_service: true
  job_datamover_ks_user: true
  job_image_repo_sync: true
  job_wlm_cloud_trust: true
  job_wlm_db_drop: false
  job_wlm_db_init: true
  job_wlm_db_sync: true
  job_wlm_ks_endpoints: true
  job_wlm_ks_service: true
  job_wlm_ks_user: true
  job_wlm_rabbit_init: true
  network_policy_datamover: false
  network_policy_wlm: false
  nfs_pv: true
  nfs_pvc: true
  pdb_datamover_api: true
  pdb_wlm_api: true
  secret_db_datamover: true
  secret_db_wlm: true
  secret_ingress_tls_datamover: true
  secret_ingress_tls_wlm: true
  secret_keystone: true
  secret_rabbitmq_wlm: true
  service_datamover_api: true
  service_ingress_datamover_api: true
  service_ingress_wlm_api: true
  service_wlm_api: true
  wlm_configmap_bin: true
  wlm_configmap_etc: true
network:
  api:
    ingress:
      annotations:
        nginx.ingress.kubernetes.io/backend-protocol: https
  datamover_api:
    external_policy_local: false
    ingress:
      annotations:
        nginx.ingress.kubernetes.io/rewrite-target: /
      classes:
        cluster: nginx-cluster
        namespace: nginx
      public: true
    node_port:
      enabled: false
      port: 30902
  wlm_api:
    external_policy_local: false
    ingress:
      annotations:
        nginx.ingress.kubernetes.io/rewrite-target: /
      classes:
        cluster: nginx-cluster
        namespace: nginx
      public: true
    node_port:
      enabled: false
      port: 30901
network_policy:
  triliovault_datamover:
    egress:
    - {}
    ingress:
    - {}
  triliovault_wlm:
    egress:
    - {}
    ingress:
    - {}
pod:
  affinity:
    anti:
      topologyKey:
        default: kubernetes.io/hostname
      type:
        default: preferredDuringSchedulingIgnoredDuringExecution
      weight:
        default: 10
  lifecycle:
    disruption_budget:
      datamover_api:
        min_available: 0
      wlm_api:
        min_available: 0
    termination_grace_period:
      datamover:
        timeout: 30
      datamover_api:
        timeout: 30
      wlm_api:
        timeout: 30
      wlm_cron:
        timeout: 30
      wlm_scheduler:
        timeout: 30
      wlm_workloads:
        timeout: 30
    upgrades:
      daemonsets:
        datamover:
          enabled: true
          max_unavailable: 1
          min_ready_seconds: 0
        pod_replacement_strategy: RollingUpdate
      deployments:
        pod_replacement_strategy: RollingUpdate
        revision_history: 3
        rolling_update:
          max_surge: 3
          max_unavailable: 1
  mounts:
    triliovault_datamover:
      init_container: null
      triliovault_datamover:
        volumeMounts: null
        volumes: null
    triliovault_datamover_api:
      init_container: null
      triliovault_datamover_api:
        volumeMounts: null
        volumes: null
    triliovault_datamover_db_sync:
      triliovault_wlm_db_sync:
        volumeMounts: null
        volumes: null
    triliovault_tests:
      init_container: null
      triliovault_tests:
        volumeMounts: null
        volumes: null
    triliovault_wlm_api:
      init_container: null
      triliovault_wlm_api:
        volumeMounts: null
        volumes: null
    triliovault_wlm_cron:
      init_container: null
      triliovault_wlm_cron:
        volumeMounts: null
        volumes: null
    triliovault_wlm_db_sync:
      triliovault_wlm_db_sync:
        volumeMounts: null
        volumes: null
    triliovault_wlm_scheduler:
      init_container: null
      triliovault_wlm_scheduler:
        volumeMounts: null
        volumes: null
    triliovault_wlm_workloads:
      init_container: null
      triliovault_wlm_workloads:
        volumeMounts: null
        volumes: null
  replicas:
    triliovault_datamover_api: 3
    triliovault_wlm_api: 3
    triliovault_wlm_cron: 1
    triliovault_wlm_scheduler: 1
    triliovault_wlm_workloads: 3
  resources:
    datamover:
      limits:
        cpu: 2000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
    datamover_api:
      limits:
        cpu: 2000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
    enabled: false
    jobs:
      bootstrap:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      db_drop:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      db_init:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      db_sync:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      image_repo_sync:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      ks_endpoints:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      ks_service:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      ks_user:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      rabbit_init:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
      tests:
        limits:
          cpu: 2000m
          memory: 1024Mi
        requests:
          cpu: 100m
          memory: 128Mi
    wlm_api:
      limits:
        cpu: 2000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
    wlm_cron:
      limits:
        cpu: 2000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
    wlm_scheduler:
      limits:
        cpu: 2000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
    wlm_workloads:
      limits:
        cpu: 2000m
        memory: 1024Mi
      requests:
        cpu: 100m
        memory: 128Mi
  security_context:
    triliovault:
      container:
        triliovault_datamover:
          privileged: true
          runAsUser: 0
        triliovault_datamover_api:
          readOnlyRootFilesystem: false
          runAsUser: 0
        triliovault_volume_usage_audit:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
        triliovault_wlm_api:
          allowPrivilegeEscalation: true
          privileged: true
          readOnlyRootFilesystem: false
          runAsUser: 0
        triliovault_wlm_cron:
          allowPrivilegeEscalation: true
          privileged: true
          readOnlyRootFilesystem: true
          runAsUser: 0
        triliovault_wlm_scheduler:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          runAsUser: 64060
        triliovault_wlm_workloads:
          allowPrivilegeEscalation: true
          privileged: true
          readOnlyRootFilesystem: false
          runAsUser: 0
      pod:
        runAsUser: 42424
release_group: null
secrets:
  identity:
    admin: triliovault-keystone-admin
    test: triliovault-keystone-test
    triliovault_datamover: triliovault-datamover-keystone-user
    triliovault_wlm: triliovault-wlm-keystone-user
  oslo_db:
    admin: triliovault-db-admin
    triliovault_datamover: triliovault-datamover-db-user
    triliovault_wlm: triliovault-wlm-db-user
  oslo_messaging:
    admin: triliovault-rabbitmq-admin
    triliovault_wlm: triliovault-wlm-rabbitmq-user
  tls:
    datamover:
      datamover_api:
        internal: triliovault-datamover-tls-api
        public: triliovault-datamover-tls-public
    workloads:
      wlm_api:
        internal: triliovault-wlm-tls-api
        public: triliovault-wlm-tls-public

HOOKS:
MANIFEST:

---
# Source: triliovault/templates/pdb-datamover-api.yaml

---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: triliovault-datamover-api
spec:
  minAvailable: 0
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault-datamover
      component: datamover-api

---
# Source: triliovault/templates/pdb-wlm-api.yaml

---
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: triliovault-wlm-api
spec:
  minAvailable: 0
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault-wlm
      component: wlm-api

---
# Source: triliovault/templates/configmap-etc-datamover.yaml




---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-datamover-etc
type: Opaque
data:
  triliovault-datamover-api.conf: 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
  triliovault-datamover.conf: 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
  logging.conf: W2Zvcm1hdHRlcl9jb250ZXh0XQpjbGFzcyA9IG9zbG9fbG9nLmZvcm1hdHRlcnMuQ29udGV4dEZvcm1hdHRlcgpkYXRlZm10ID0gJVktJW0tJWQgJUg6JU06JVMKW2Zvcm1hdHRlcl9kZWZhdWx0XQpkYXRlZm10ID0gJVktJW0tJWQgJUg6JU06JVMKZm9ybWF0ID0gJShtZXNzYWdlKXMKW2Zvcm1hdHRlcnNdCmtleXMgPSBjb250ZXh0LGRlZmF1bHQKW2hhbmRsZXJfbnVsbF0KYXJncyA9ICgpCmNsYXNzID0gbG9nZ2luZy5OdWxsSGFuZGxlcgpmb3JtYXR0ZXIgPSBkZWZhdWx0CltoYW5kbGVyX3N0ZGVycl0KYXJncyA9IChzeXMuc3RkZXJyLCkKY2xhc3MgPSBTdHJlYW1IYW5kbGVyCmZvcm1hdHRlciA9IGNvbnRleHQKW2hhbmRsZXJfc3Rkb3V0XQphcmdzID0gKHN5cy5zdGRvdXQsKQpjbGFzcyA9IFN0cmVhbUhhbmRsZXIKZm9ybWF0dGVyID0gY29udGV4dApbaGFuZGxlcnNdCmtleXMgPSBzdGRvdXQsc3RkZXJyLG51bGwKW2xvZ2dlcl9hbXFwXQpoYW5kbGVycyA9IApsZXZlbCA9IFdBUk5JTkcKcXVhbG5hbWUgPSBhbXFwCltsb2dnZXJfYW1xcGxpYl0KaGFuZGxlcnMgPSAKbGV2ZWwgPSBXQVJOSU5HCnF1YWxuYW1lID0gYW1xcGxpYgpbbG9nZ2VyX2JvdG9dCmhhbmRsZXJzID0gCmxldmVsID0gV0FSTklORwpxdWFsbmFtZSA9IGJvdG8KW2xvZ2dlcl9kYXRhbW92ZXJdCmhhbmRsZXJzID0gCmxldmVsID0gSU5GTwpxdWFsbmFtZSA9IGRhdGFtb3ZlcgpbbG9nZ2VyX2V2ZW50bGV0d3NnaV0KaGFuZGxlcnMgPSAKbGV2ZWwgPSBXQVJOSU5HCnF1YWxuYW1lID0gZXZlbnRsZXQud3NnaS5zZXJ2ZXIKW2xvZ2dlcl9vcy5icmlja10KaGFuZGxlcnMgPSAKbGV2ZWwgPSBJTkZPCnF1YWxuYW1lID0gb3MuYnJpY2sKW2xvZ2dlcl9yb290XQpoYW5kbGVycyA9IHN0ZG91dApsZXZlbCA9IFdBUk5JTkcKW2xvZ2dlcl9zcWxhbGNoZW15XQpoYW5kbGVycyA9IApsZXZlbCA9IFdBUk5JTkcKcXVhbG5hbWUgPSBzcWxhbGNoZW15Cltsb2dnZXJzXQprZXlzID0gcm9vdCxkYXRhbW92ZXIsb3MuYnJpY2sK
  policy.yaml: e30K
  triliovault-object-store.conf: W0RFRkFVTFRdCmxvZ19jb25maWdfYXBwZW5kID0gL2V0Yy90cmlsaW92YXVsdC1vYmplY3Qtc3RvcmUvbG9nZ2luZy5jb25mCnZhdWx0X3MzX2FjY2Vzc19rZXlfaWQgPSAKdmF1bHRfczNfYXV0aF92ZXJzaW9uID0gREVGQVVMVAp2YXVsdF9zM19idWNrZXQgPSAKdmF1bHRfczNfZW5kcG9pbnRfdXJsID0gCnZhdWx0X3MzX3JlZ2lvbl9uYW1lID0gCnZhdWx0X3MzX3NlY3JldF9hY2Nlc3Nfa2V5ID0gCnZhdWx0X3MzX3NpZ25hdHVyZV92ZXJzaW9uID0gZGVmYXVsdAp2YXVsdF9zM19zc2wgPSBmYWxzZQp2YXVsdF9zM19zc2xfY2VydCA9IC9ldGMvdHJpbGlvdmF1bHQtd2xtL3MzLWNlcnQucGVtCnZhdWx0X3N0b3JhZ2VfbmZzX2V4cG9ydCA9IFRyaWxpb1ZhdWx0CnZhdWx0X3N0b3JhZ2VfdHlwZSA9IHMzCnZlcmJvc2UgPSB0cnVlCltzM2Z1c2Vfc3lzX2FkbWluXQpoZWxwZXJfY29tbWFuZCA9IHN1ZG8gL3Vzci9iaW4vd29ya2xvYWRtZ3Itcm9vdHdyYXAgL2V0Yy90cmlsaW92YXVsdC9yb290d3JhcC5jb25mIHByaXZzZXAtaGVscGVyCg==
  fuse.conf: IyAvZXRjL2Z1c2UuY29uZiAtIENvbmZpZ3VyYXRpb24gZmlsZSBmb3IgRmlsZXN5c3RlbSBpbiBVc2Vyc3BhY2UgKEZVU0UpCgojIFNldCB0aGUgbWF4aW11bSBudW1iZXIgb2YgRlVTRSBtb3VudHMgYWxsb3dlZCB0byBub24tcm9vdCB1c2Vycy4KIyBUaGUgZGVmYXVsdCBpcyAxMDAwLgptb3VudF9tYXggPSAyMDAwCgojIEFsbG93IG5vbi1yb290IHVzZXJzIHRvIHNwZWNpZnkgdGhlIGFsbG93X290aGVyIG9yIGFsbG93X3Jvb3QgbW91bnQgb3B0aW9ucy4KdXNlcl9hbGxvd19vdGhlcgo=
  s3-cert.pem: 

---
# Source: triliovault/templates/configmap-etc-wlm.yaml





---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-wlm-etc
type: Opaque
data:
  triliovault-wlm.conf: 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
  logging.conf: W2Zvcm1hdHRlcl9jb250ZXh0XQpjbGFzcyA9IG9zbG9fbG9nLmZvcm1hdHRlcnMuQ29udGV4dEZvcm1hdHRlcgpkYXRlZm10ID0gJVktJW0tJWQgJUg6JU06JVMKW2Zvcm1hdHRlcl9kZWZhdWx0XQpkYXRlZm10ID0gJVktJW0tJWQgJUg6JU06JVMKZm9ybWF0ID0gJShtZXNzYWdlKXMKW2Zvcm1hdHRlcnNdCmtleXMgPSBjb250ZXh0LGRlZmF1bHQKW2hhbmRsZXJfbnVsbF0KYXJncyA9ICgpCmNsYXNzID0gbG9nZ2luZy5OdWxsSGFuZGxlcgpmb3JtYXR0ZXIgPSBkZWZhdWx0CltoYW5kbGVyX3N0ZGVycl0KYXJncyA9IChzeXMuc3RkZXJyLCkKY2xhc3MgPSBTdHJlYW1IYW5kbGVyCmZvcm1hdHRlciA9IGNvbnRleHQKW2hhbmRsZXJfc3Rkb3V0XQphcmdzID0gKHN5cy5zdGRvdXQsKQpjbGFzcyA9IFN0cmVhbUhhbmRsZXIKZm9ybWF0dGVyID0gY29udGV4dApbaGFuZGxlcnNdCmtleXMgPSBzdGRvdXQsc3RkZXJyLG51bGwKW2xvZ2dlcl9hbXFwXQpoYW5kbGVycyA9IApsZXZlbCA9IFdBUk5JTkcKcXVhbG5hbWUgPSBhbXFwCltsb2dnZXJfYW1xcGxpYl0KaGFuZGxlcnMgPSAKbGV2ZWwgPSBXQVJOSU5HCnF1YWxuYW1lID0gYW1xcGxpYgpbbG9nZ2VyX2JvdG9dCmhhbmRsZXJzID0gCmxldmVsID0gV0FSTklORwpxdWFsbmFtZSA9IGJvdG8KW2xvZ2dlcl9kYXRhbW92ZXJdCmhhbmRsZXJzID0gCmxldmVsID0gSU5GTwpxdWFsbmFtZSA9IGRhdGFtb3ZlcgpbbG9nZ2VyX2V2ZW50bGV0d3NnaV0KaGFuZGxlcnMgPSAKbGV2ZWwgPSBXQVJOSU5HCnF1YWxuYW1lID0gZXZlbnRsZXQud3NnaS5zZXJ2ZXIKW2xvZ2dlcl9vcy5icmlja10KaGFuZGxlcnMgPSAKbGV2ZWwgPSBJTkZPCnF1YWxuYW1lID0gb3MuYnJpY2sKW2xvZ2dlcl9yb290XQpoYW5kbGVycyA9IHN0ZG91dApsZXZlbCA9IFdBUk5JTkcKW2xvZ2dlcl9zcWxhbGNoZW15XQpoYW5kbGVycyA9IApsZXZlbCA9IFdBUk5JTkcKcXVhbG5hbWUgPSBzcWxhbGNoZW15Cltsb2dnZXJzXQprZXlzID0gcm9vdCxkYXRhbW92ZXIsb3MuYnJpY2sK
  api-paste.ini: ICAKW2NvbXBvc2l0ZTpvc2FwaV93b3JrbG9hZHNdCnVzZSA9IGNhbGw6d29ya2xvYWRtZ3IuYXBpOnJvb3RfYXBwX2ZhY3RvcnkKLyA9IGFwaXZlcnNpb25zCi92MSA9IG9wZW5zdGFja193b3JrbG9hZHNfYXBpX3YxCiAgICAKW2NvbXBvc2l0ZTpvcGVuc3RhY2tfd29ya2xvYWRzX2FwaV92MV0KdXNlID0gY2FsbDp3b3JrbG9hZG1nci5hcGkubWlkZGxld2FyZS5hdXRoOnBpcGVsaW5lX2ZhY3RvcnkKbm9hdXRoID0gZmF1bHR3cmFwIHNpemVsaW1pdCBub2F1dGggYXBpdjEKa2V5c3RvbmUgPSBmYXVsdHdyYXAgc2l6ZWxpbWl0IGF1dGh0b2tlbiBrZXlzdG9uZWNvbnRleHQgYXBpdjEKa2V5c3RvbmVfbm9saW1pdCA9IGZhdWx0d3JhcCBzaXplbGltaXQgYXV0aHRva2VuIGtleXN0b25lY29udGV4dCBhcGl2MQoKW2ZpbHRlcjpmYXVsdHdyYXBdCnBhc3RlLmZpbHRlcl9mYWN0b3J5ID0gd29ya2xvYWRtZ3IuYXBpLm1pZGRsZXdhcmUuZmF1bHQ6RmF1bHRXcmFwcGVyLmZhY3RvcnkKCltmaWx0ZXI6bm9hdXRoXQpwYXN0ZS5maWx0ZXJfZmFjdG9yeSA9IHdvcmtsb2FkbWdyLmFwaS5taWRkbGV3YXJlLmF1dGg6Tm9BdXRoTWlkZGxld2FyZS5mYWN0b3J5CgpbZmlsdGVyOnNpemVsaW1pdF0KcGFzdGUuZmlsdGVyX2ZhY3RvcnkgPSBvc2xvX21pZGRsZXdhcmUuc2l6ZWxpbWl0OlJlcXVlc3RCb2R5U2l6ZUxpbWl0ZXIuZmFjdG9yeQoKW2FwcDphcGl2MV0KcGFzdGUuYXBwX2ZhY3RvcnkgPSB3b3JrbG9hZG1nci5hcGkudjEucm91dGVyOkFQSVJvdXRlci5mYWN0b3J5CgpbcGlwZWxpbmU6YXBpdmVyc2lvbnNdCnBpcGVsaW5lID0gZmF1bHR3cmFwIG9zd29ya2xvYWRzdmVyc2lvbmFwcAoKW2FwcDpvc3dvcmtsb2Fkc3ZlcnNpb25hcHBdCnBhc3RlLmFwcF9mYWN0b3J5ID0gd29ya2xvYWRtZ3IuYXBpLnZlcnNpb25zOlZlcnNpb25zLmZhY3RvcnkKCltmaWx0ZXI6a2V5c3RvbmVjb250ZXh0XQpwYXN0ZS5maWx0ZXJfZmFjdG9yeSA9IHdvcmtsb2FkbWdyLmFwaS5taWRkbGV3YXJlLmF1dGg6V29ya2xvYWRNZ3JLZXlzdG9uZUNvbnRleHQuZmFjdG9yeQoKW2ZpbHRlcjphdXRodG9rZW5dCnBhc3RlLmZpbHRlcl9mYWN0b3J5ID0gIGtleXN0b25lbWlkZGxld2FyZS5hdXRoX3Rva2VuOmZpbHRlcl9mYWN0b3J5CmF1dGhfaG9zdCA9IGtleXN0b25lLWFwaS5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsCmF1dGhfcG9ydCA9IDUwMDAKYXV0aF9wcm90b2NvbCA9IGh0dHBzCmFkbWluX3RlbmFudF9uYW1lID0gc2VydmljZQpwcm9qZWN0X25hbWUgPSBzZXJ2aWNlCmFkbWluX3VzZXIgPSB0cmlsaW92YXVsdAphZG1pbl9wYXNzd29yZCA9IHBhc3N3b3JkCnNpZ25pbmdfZGlyID0gL3Zhci9jYWNoZS93b3JrbG9hZG1ncgppbnNlY3VyZSA9IFRydWUK
  policy.yaml: e30K
  triliovault-object-store.conf: W0RFRkFVTFRdCmxvZ19jb25maWdfYXBwZW5kID0gL2V0Yy90cmlsaW92YXVsdC1vYmplY3Qtc3RvcmUvbG9nZ2luZy5jb25mCnZhdWx0X3MzX2FjY2Vzc19rZXlfaWQgPSAKdmF1bHRfczNfYXV0aF92ZXJzaW9uID0gREVGQVVMVAp2YXVsdF9zM19idWNrZXQgPSAKdmF1bHRfczNfZW5kcG9pbnRfdXJsID0gCnZhdWx0X3MzX3JlZ2lvbl9uYW1lID0gCnZhdWx0X3MzX3NlY3JldF9hY2Nlc3Nfa2V5ID0gCnZhdWx0X3MzX3NpZ25hdHVyZV92ZXJzaW9uID0gZGVmYXVsdAp2YXVsdF9zM19zc2wgPSBmYWxzZQp2YXVsdF9zM19zc2xfY2VydCA9IC9ldGMvdHJpbGlvdmF1bHQtd2xtL3MzLWNlcnQucGVtCnZhdWx0X3N0b3JhZ2VfbmZzX2V4cG9ydCA9IFRyaWxpb1ZhdWx0CnZhdWx0X3N0b3JhZ2VfdHlwZSA9IHMzCnZlcmJvc2UgPSB0cnVlCltzM2Z1c2Vfc3lzX2FkbWluXQpoZWxwZXJfY29tbWFuZCA9IHN1ZG8gL3Vzci9iaW4vd29ya2xvYWRtZ3Itcm9vdHdyYXAgL2V0Yy90cmlsaW92YXVsdC9yb290d3JhcC5jb25mIHByaXZzZXAtaGVscGVyCg==
  fuse.conf: IyAvZXRjL2Z1c2UuY29uZiAtIENvbmZpZ3VyYXRpb24gZmlsZSBmb3IgRmlsZXN5c3RlbSBpbiBVc2Vyc3BhY2UgKEZVU0UpCgojIFNldCB0aGUgbWF4aW11bSBudW1iZXIgb2YgRlVTRSBtb3VudHMgYWxsb3dlZCB0byBub24tcm9vdCB1c2Vycy4KIyBUaGUgZGVmYXVsdCBpcyAxMDAwLgptb3VudF9tYXggPSAyMDAwCgojIEFsbG93IG5vbi1yb290IHVzZXJzIHRvIHNwZWNpZnkgdGhlIGFsbG93X290aGVyIG9yIGFsbG93X3Jvb3QgbW91bnQgb3B0aW9ucy4KdXNlcl9hbGxvd19vdGhlcgo=
  s3-cert.pem: 

---
# Source: triliovault/templates/secret-datamover-db.yaml

---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-db-admin
type: Opaque
data:
  DB_CONNECTION: bXlzcWwrcHlteXNxbDovL3Jvb3Q6cGFzc3dvcmRAbWFyaWFkYi5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsOjMzMDYvZG1hcGk=
---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-datamover-db-user
type: Opaque
data:
  DB_CONNECTION: bXlzcWwrcHlteXNxbDovL2RtYXBpOnBhc3N3b3JkQG1hcmlhZGIuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDozMzA2L2RtYXBp

---
# Source: triliovault/templates/secret-keystone.yaml

---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-keystone-admin
type: Opaque
data:  
  OS_AUTH_URL: aHR0cHM6Ly9rZXlzdG9uZS1hcGkuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDo1MDAwL3Yz
  OS_REGION_NAME: UmVnaW9uT25l
  OS_INTERFACE: aW50ZXJuYWw=
  OS_PROJECT_DOMAIN_NAME: c2VydmljZQ==
  OS_PROJECT_NAME: c2VydmljZQ==
  OS_USER_DOMAIN_NAME: c2VydmljZQ==
  OS_USERNAME: YWRtaW4=
  OS_PASSWORD: cGFzc3dvcmQ=
  OS_DEFAULT_DOMAIN: ZGVmYXVsdA==
  OS_CACERT: L2V0Yy9zc2wvY2VydHMvb3BlbnN0YWNrLWhlbG0uY3J0
---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-datamover-keystone-user
type: Opaque
data:  
  OS_AUTH_URL: aHR0cHM6Ly9rZXlzdG9uZS1hcGkuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDo1MDAwL3Yz
  OS_REGION_NAME: UmVnaW9uT25l
  OS_INTERFACE: aW50ZXJuYWw=
  OS_PROJECT_DOMAIN_NAME: c2VydmljZQ==
  OS_PROJECT_NAME: c2VydmljZQ==
  OS_USER_DOMAIN_NAME: c2VydmljZQ==
  OS_USERNAME: ZG1hcGk=
  OS_PASSWORD: cGFzc3dvcmQ=
  OS_DEFAULT_DOMAIN: ZGVmYXVsdA==
  OS_CACERT: L2V0Yy9zc2wvY2VydHMvb3BlbnN0YWNrLWhlbG0uY3J0
---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-wlm-keystone-user
type: Opaque
data:  
  OS_AUTH_URL: aHR0cHM6Ly9rZXlzdG9uZS1hcGkuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDo1MDAwL3Yz
  OS_REGION_NAME: UmVnaW9uT25l
  OS_INTERFACE: aW50ZXJuYWw=
  OS_PROJECT_DOMAIN_NAME: c2VydmljZQ==
  OS_PROJECT_NAME: c2VydmljZQ==
  OS_USER_DOMAIN_NAME: c2VydmljZQ==
  OS_USERNAME: dHJpbGlvdmF1bHQ=
  OS_PASSWORD: cGFzc3dvcmQ=
  OS_DEFAULT_DOMAIN: ZGVmYXVsdA==
  OS_CACERT: L2V0Yy9zc2wvY2VydHMvb3BlbnN0YWNrLWhlbG0uY3J0

---
# Source: triliovault/templates/secret-wlm-db.yaml

---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-db-admin
type: Opaque
data:
  DB_CONNECTION: bXlzcWwrcHlteXNxbDovL3Jvb3Q6cGFzc3dvcmRAbWFyaWFkYi5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsOjMzMDYvd29ya2xvYWRtZ3I=
---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-wlm-db-user
type: Opaque
data:
  DB_CONNECTION: bXlzcWwrcHlteXNxbDovL3dvcmtsb2FkbWdyOnBhc3N3b3JkQG1hcmlhZGIuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDozMzA2L3dvcmtsb2FkbWdy

---
# Source: triliovault/templates/secret-wlm-rabbitmq.yaml

---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-rabbitmq-admin
type: Opaque
data:
  RABBITMQ_CONNECTION: cmFiYml0Oi8vcmFiYml0bXE6cGFzc3dvcmRAcmFiYml0bXEuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDoxNTY3Mi90cmlsaW92YXVsdA==
---
apiVersion: v1
kind: Secret
metadata:
  name: triliovault-wlm-rabbitmq-user
type: Opaque
data:
  RABBITMQ_CONNECTION: cmFiYml0Oi8vdHJpbGlvdmF1bHQ6cGFzc3dvcmRAcmFiYml0bXEuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbDoxNTY3Mi90cmlsaW92YXVsdA==

---
# Source: triliovault/templates/configmap-bin-datamover.yaml

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: triliovault-datamover-bin
data:
  db-init.py: |    
    #!/usr/bin/env python
    
    # Creates db and user for an OpenStack Service:
    # Set ROOT_DB_CONNECTION and DB_CONNECTION environment variables to contain
    # SQLAlchemy strings for the root connection to the database and the one you
    # wish the service to use. Alternatively, you can use an ini formatted config
    # at the location specified by OPENSTACK_CONFIG_FILE, and extract the string
    # from the key OPENSTACK_CONFIG_DB_KEY, in the section specified by
    # OPENSTACK_CONFIG_DB_SECTION.
    
    import os
    import sys
    try:
        import ConfigParser
        PARSER_OPTS = {}
    except ImportError:
        import configparser as ConfigParser
        PARSER_OPTS = {"strict": False}
    import logging
    from sqlalchemy import create_engine
    
    # Create logger, console handler and formatter
    logger = logging.getLogger('OpenStack-Helm DB Init')
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Set the formatter and add the handler
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    
    
    # Get the connection string for the service db root user
    if "ROOT_DB_CONNECTION" in os.environ:
        db_connection = os.environ['ROOT_DB_CONNECTION']
        logger.info('Got DB root connection')
    else:
        logger.critical('environment variable ROOT_DB_CONNECTION not set')
        sys.exit(1)
    
    mysql_x509 = os.getenv('MARIADB_X509', "")
    ssl_args = {}
    if mysql_x509:
        ssl_args = {'ssl': {'ca': '/etc/mysql/certs/ca.crt',
                    'key': '/etc/mysql/certs/tls.key',
                    'cert': '/etc/mysql/certs/tls.crt'}}
    
    # Get the connection string for the service db
    if "OPENSTACK_CONFIG_FILE" in os.environ:
        os_conf = os.environ['OPENSTACK_CONFIG_FILE']
        if "OPENSTACK_CONFIG_DB_SECTION" in os.environ:
            os_conf_section = os.environ['OPENSTACK_CONFIG_DB_SECTION']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_SECTION not set')
            sys.exit(1)
        if "OPENSTACK_CONFIG_DB_KEY" in os.environ:
            os_conf_key = os.environ['OPENSTACK_CONFIG_DB_KEY']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_KEY not set')
            sys.exit(1)
        try:
            config = ConfigParser.RawConfigParser(**PARSER_OPTS)
            logger.info("Using {0} as db config source".format(os_conf))
            config.read(os_conf)
            logger.info("Trying to load db config from {0}:{1}".format(
                os_conf_section, os_conf_key))
            user_db_conn = config.get(os_conf_section, os_conf_key)
            logger.info("Got config from {0}".format(os_conf))
        except:
            logger.critical("Tried to load config from {0} but failed.".format(os_conf))
            raise
    elif "DB_CONNECTION" in os.environ:
        user_db_conn = os.environ['DB_CONNECTION']
        logger.info('Got config from DB_CONNECTION env var')
    else:
        logger.critical('Could not get db config, either from config file or env var')
        sys.exit(1)
    
    # Root DB engine
    try:
        root_engine_full = create_engine(db_connection)
        root_user = root_engine_full.url.username
        root_password = root_engine_full.url.password
        drivername = root_engine_full.url.drivername
        host = root_engine_full.url.host
        port = root_engine_full.url.port
        root_engine_url = ''.join([drivername, '://', root_user, ':', root_password, '@', host, ':', str (port)])
        root_engine = create_engine(root_engine_url, connect_args=ssl_args)
        connection = root_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1} as {2}".format(
            host, port, root_user))
    except:
        logger.critical('Could not connect to database as root user')
        raise
    
    # User DB engine
    try:
        user_engine = create_engine(user_db_conn, connect_args=ssl_args)
        # Get our user data out of the user_engine
        database = user_engine.url.database
        user = user_engine.url.username
        password = user_engine.url.password
        logger.info('Got user db config')
    except:
        logger.critical('Could not get user database config')
        raise
    
    # Create DB
    try:
        root_engine.execute("CREATE DATABASE IF NOT EXISTS {0}".format(database))
        logger.info("Created database {0}".format(database))
    except:
        logger.critical("Could not create database {0}".format(database))
        raise
    
    # Create DB User
    try:
        root_engine.execute(
            "GRANT ALL ON `{0}`.* TO \'{1}\'@\'%%\' IDENTIFIED BY \'{2}\' {3}".format(
                database, user, password, mysql_x509))
        logger.info("Created user {0} for {1}".format(user, database))
    except:
        logger.critical("Could not create user {0} for {1}".format(user, database))
        raise
    
    # Test connection
    try:
        connection = user_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1}/{2} as {3}".format(
            host, port, database, user))
    except:
        logger.critical('Could not connect to database as user')
        raise
    
    logger.info('Finished DB Management')
  db-sync.sh: |
    #!/bin/bash
    
    
    
    set -ex
    exec dmapi-dbsync
    
  db-drop.py: |    
    #!/usr/bin/env python
    
    # Drops db and user for an OpenStack Service:
    # Set ROOT_DB_CONNECTION and DB_CONNECTION environment variables to contain
    # SQLAlchemy strings for the root connection to the database and the one you
    # wish the service to use. Alternatively, you can use an ini formatted config
    # at the location specified by OPENSTACK_CONFIG_FILE, and extract the string
    # from the key OPENSTACK_CONFIG_DB_KEY, in the section specified by
    # OPENSTACK_CONFIG_DB_SECTION.
    
    import os
    import sys
    try:
        import ConfigParser
        PARSER_OPTS = {}
    except ImportError:
        import configparser as ConfigParser
        PARSER_OPTS = {"strict": False}
    import logging
    from sqlalchemy import create_engine
    
    # Create logger, console handler and formatter
    logger = logging.getLogger('OpenStack-Helm DB Drop')
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Set the formatter and add the handler
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    
    
    # Get the connection string for the service db root user
    if "ROOT_DB_CONNECTION" in os.environ:
        db_connection = os.environ['ROOT_DB_CONNECTION']
        logger.info('Got DB root connection')
    else:
        logger.critical('environment variable ROOT_DB_CONNECTION not set')
        sys.exit(1)
    
    mysql_x509 = os.getenv('MARIADB_X509', "")
    ssl_args = {}
    if mysql_x509:
        ssl_args = {'ssl': {'ca': '/etc/mysql/certs/ca.crt',
                            'key': '/etc/mysql/certs/tls.key',
                            'cert': '/etc/mysql/certs/tls.crt'}}
    
    # Get the connection string for the service db
    if "OPENSTACK_CONFIG_FILE" in os.environ:
        os_conf = os.environ['OPENSTACK_CONFIG_FILE']
        if "OPENSTACK_CONFIG_DB_SECTION" in os.environ:
            os_conf_section = os.environ['OPENSTACK_CONFIG_DB_SECTION']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_SECTION not set')
            sys.exit(1)
        if "OPENSTACK_CONFIG_DB_KEY" in os.environ:
            os_conf_key = os.environ['OPENSTACK_CONFIG_DB_KEY']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_KEY not set')
            sys.exit(1)
        try:
            config = ConfigParser.RawConfigParser(**PARSER_OPTS)
            logger.info("Using {0} as db config source".format(os_conf))
            config.read(os_conf)
            logger.info("Trying to load db config from {0}:{1}".format(
                os_conf_section, os_conf_key))
            user_db_conn = config.get(os_conf_section, os_conf_key)
            logger.info("Got config from {0}".format(os_conf))
        except:
            logger.critical("Tried to load config from {0} but failed.".format(os_conf))
            raise
    elif "DB_CONNECTION" in os.environ:
        user_db_conn = os.environ['DB_CONNECTION']
        logger.info('Got config from DB_CONNECTION env var')
    else:
        logger.critical('Could not get db config, either from config file or env var')
        sys.exit(1)
    
    # Root DB engine
    try:
        root_engine_full = create_engine(db_connection)
        root_user = root_engine_full.url.username
        root_password = root_engine_full.url.password
        drivername = root_engine_full.url.drivername
        host = root_engine_full.url.host
        port = root_engine_full.url.port
        root_engine_url = ''.join([drivername, '://', root_user, ':', root_password, '@', host, ':', str (port)])
        root_engine = create_engine(root_engine_url, connect_args=ssl_args)
        connection = root_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1} as {2}".format(
            host, port, root_user))
    except:
        logger.critical('Could not connect to database as root user')
        raise
    
    # User DB engine
    try:
        user_engine = create_engine(user_db_conn, connect_args=ssl_args)
        # Get our user data out of the user_engine
        database = user_engine.url.database
        user = user_engine.url.username
        password = user_engine.url.password
        logger.info('Got user db config')
    except:
        logger.critical('Could not get user database config')
        raise
    
    # Delete DB
    try:
        root_engine.execute("DROP DATABASE IF EXISTS {0}".format(database))
        logger.info("Deleted database {0}".format(database))
    except:
        logger.critical("Could not drop database {0}".format(database))
        raise
    
    # Delete DB User
    try:
        root_engine.execute("DROP USER IF EXISTS {0}".format(user))
        logger.info("Deleted user {0}".format(user))
    except:
        logger.critical("Could not delete user {0}".format(user))
        raise
    
    logger.info('Finished DB Management')
  triliovault-datamover-api-init.sh: | 
    #!/bin/bash
    
    
    
    set -ex
    
    touch /tmp/pod-shared/triliovault-datamover-api-my-ip.conf
    
    host_interface=""
    if [[ -z $host_interface ]]; then
        # search for interface with default routing
        # If there is not default gateway, exit
        host_interface=$(ip -4 route list 0/0 | awk -F 'dev' '{ print $2; exit }' | awk '{ print $1 }') || exit 1
    fi
    
    datamover_api_ip_address=$(ip a s $host_interface | grep 'inet ' | awk '{print $2}' | awk -F "/" '{print $1}' | head -1)
    
    if [ -z "${datamover_api_ip_address}" ] ; then
      echo "Var my_ip is empty"
      exit 1
    fi
    
    tee > /tmp/pod-shared-triliovault-datamover-api/triliovault-datamover-api-my-ip.conf << EOF
    [DEFAULT]
    dmapi_link_prefix = http://${datamover_api_ip_address}:8784
    dmapi_listen = $datamover_api_ip_address
    my_ip = $datamover_api_ip_address
    EOF
    
    
    
    
    
  triliovault-datamover-api.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    COMMAND="${@:-start}"
    
    function start () {
      exec /usr/bin/python3 /usr/bin/dmapi-api \
           --config-file /etc/triliovault-datamover/triliovault-datamover-api.conf \
           --config-file /tmp/pod-shared-triliovault-datamover-api/triliovault-datamover-api-my-ip.conf
    }
    
    function stop () {
      kill -TERM 1
    }
    
    $COMMAND
    
    
  triliovault-datamover.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    
    COMMAND="${@:-start}"
    
    function start () {
      exec /usr/bin/python3 /usr/bin/dmapi-api \
           --config-file /etc/triliovault-datamover/triliovault-datamover-api.conf \
           --config-file /tmp/pod-shared-triliovault-datamover-api/triliovault-datamover-api-my-ip.conf
    
      
    
      # Start triliovault datamover service
      /usr/bin/python3 /usr/bin/tvault-contego \
        --config-file=/usr/share/nova/nova-dist.conf --config-file=/etc/nova/nova.conf \
        --config-file=/etc/triliovault-datamover/triliovault-datamover.conf &
    
      status=$?
      if [ $status -ne 0 ]; then
        echo "Failed to start tvault contego service: $status"
        exit $status
      fi
    
    
    }
    
    function stop () {
      kill -TERM 1
    }
    
    $COMMAND
    
    
    
  ks-service.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    # Service boilerplate description
    OS_SERVICE_DESC="${OS_REGION_NAME}: ${OS_SERVICE_NAME} (${OS_SERVICE_TYPE}) service"
    
    # Get Service ID if it exists
    unset OS_SERVICE_ID
    
    # FIXME - There seems to be an issue once in a while where the
    # openstack service list fails and encounters an error message such as:
    #   Unable to establish connection to
    #   https://keystone-api.openstack.svc.cluster.local:5000/v3/auth/tokens:
    #   ('Connection aborted.', OSError("(104, 'ECONNRESET')",))
    # During an upgrade scenario, this would cause the OS_SERVICE_ID to be blank
    # and it would attempt to create a new service when it was not needed.
    # This duplciate service would sometimes be used by other services such as
    # Horizon and would give an 'Invalid Service Catalog' error.
    # This loop allows for a 'retry' of the openstack service list in an
    # attempt to get the service list as expected if it does ecounter an error.
    # This loop and recheck can be reverted once the underlying issue is addressed.
    
    # If OS_SERVICE_ID is blank then wait a few seconds to give it
    # additional time and try again
    for i in $(seq 3)
    do
      OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                       grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                       sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )
    
      # If the service was found, go ahead and exit successfully.
      if [[ -n "${OS_SERVICE_ID}" ]]; then
        exit 0
      fi
    
      sleep 2
    done
    
    # If we've reached this point and a Service ID was not found,
    # then create the service
    OS_SERVICE_ID=$(openstack service create -f value -c id \
                    --name="${OS_SERVICE_NAME}" \
                    --description "${OS_SERVICE_DESC}" \
                    --enable \
                    "${OS_SERVICE_TYPE}")
  ks-endpoints.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    # Get Service ID
    OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                      grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                        sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )
    
    # Get Endpoint ID if it exists
    OS_ENDPOINT_ID=$( openstack endpoint list  -f csv --quote none | \
                      grep "^[a-z0-9]*,${OS_REGION_NAME},${OS_SERVICE_NAME},${OS_SERVICE_TYPE},True,${OS_SVC_ENDPOINT}," | \
                      awk -F ',' '{ print $1 }' )
    
    # Making sure only a single endpoint exists for a service within a region
    if [ "$(echo $OS_ENDPOINT_ID | wc -w)" -gt "1" ]; then
      echo "More than one endpoint found, cleaning up"
      for ENDPOINT_ID in $OS_ENDPOINT_ID; do
        openstack endpoint delete ${ENDPOINT_ID}
      done
      unset OS_ENDPOINT_ID
    fi
    
    # Determine if Endpoint needs updated
    if [[ ${OS_ENDPOINT_ID} ]]; then
      OS_ENDPOINT_URL_CURRENT=$(openstack endpoint show ${OS_ENDPOINT_ID} -f value -c url)
      if [ "${OS_ENDPOINT_URL_CURRENT}" == "${OS_SERVICE_ENDPOINT}" ]; then
        echo "Endpoints Match: no action required"
        OS_ENDPOINT_UPDATE="False"
      else
        echo "Endpoints Dont Match: removing existing entries"
        openstack endpoint delete ${OS_ENDPOINT_ID}
        OS_ENDPOINT_UPDATE="True"
      fi
    else
      OS_ENDPOINT_UPDATE="True"
    fi
    
    # Update Endpoint if required
    if [[ "${OS_ENDPOINT_UPDATE}" == "True" ]]; then
      OS_ENDPOINT_ID=$( openstack endpoint create -f value -c id \
        --region="${OS_REGION_NAME}" \
        "${OS_SERVICE_ID}" \
        ${OS_SVC_ENDPOINT} \
        "${OS_SERVICE_ENDPOINT}" )
    fi
    
    # Display the Endpoint
    openstack endpoint show ${OS_ENDPOINT_ID}
  ks-user.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    shopt -s nocasematch
    
    if [[ "${SERVICE_OS_PROJECT_DOMAIN_NAME}" == "Default" ]]
    then
      PROJECT_DOMAIN_ID="default"
    else
      # Manage project domain
      PROJECT_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}" \
        "${SERVICE_OS_PROJECT_DOMAIN_NAME}")
    fi
    
    if [[ "${SERVICE_OS_USER_DOMAIN_NAME}" == "Default" ]]
    then
      USER_DOMAIN_ID="default"
    else
      # Manage user domain
      USER_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}" \
        "${SERVICE_OS_USER_DOMAIN_NAME}")
    fi
    
    shopt -u nocasematch
    
    # Manage user project
    USER_PROJECT_DESC="Service Project for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}"
    USER_PROJECT_ID=$(openstack project create --or-show --enable -f value -c id \
        --domain="${PROJECT_DOMAIN_ID}" \
        --description="${USER_PROJECT_DESC}" \
        "${SERVICE_OS_PROJECT_NAME}");
    
    # Manage user
    USER_DESC="Service User for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}/${SERVICE_OS_SERVICE_NAME}"
    USER_ID=$(openstack user create --or-show --enable -f value -c id \
        --domain="${USER_DOMAIN_ID}" \
        --project-domain="${PROJECT_DOMAIN_ID}" \
        --project="${USER_PROJECT_ID}" \
        --description="${USER_DESC}" \
        "${SERVICE_OS_USERNAME}");
    
    # Manage user password (we do this in a seperate step to ensure the password is updated if required)
    set +x
    echo "Setting user password via: openstack user set --password=xxxxxxx ${USER_ID}"
    openstack user set --password="${SERVICE_OS_PASSWORD}" "${USER_ID}"
    set -x
    
    function ks_assign_user_role () {
      if [[ "$SERVICE_OS_ROLE" == "admin" ]]
      then
        USER_ROLE_ID="$SERVICE_OS_ROLE"
      else
        USER_ROLE_ID=$(openstack role create --or-show -f value -c id "${SERVICE_OS_ROLE}");
      fi
    
      # Manage user role assignment
      openstack role add \
          --user="${USER_ID}" \
          --user-domain="${USER_DOMAIN_ID}" \
          --project-domain="${PROJECT_DOMAIN_ID}" \
          --project="${USER_PROJECT_ID}" \
          "${USER_ROLE_ID}"
    }
    
    # Manage user service role
    IFS=','
    for SERVICE_OS_ROLE in ${SERVICE_OS_ROLES}; do
      ks_assign_user_role
    done
    
    # Manage user member role
    : ${MEMBER_OS_ROLE:="member"}
    export USER_ROLE_ID=$(openstack role create --or-show -f value -c id \
        "${MEMBER_OS_ROLE}");
    ks_assign_user_role

---
# Source: triliovault/templates/configmap-bin-wlm.yaml

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: triliovault-wlm-bin
data:
  db-init.py: |    
    #!/usr/bin/env python
    
    # Creates db and user for an OpenStack Service:
    # Set ROOT_DB_CONNECTION and DB_CONNECTION environment variables to contain
    # SQLAlchemy strings for the root connection to the database and the one you
    # wish the service to use. Alternatively, you can use an ini formatted config
    # at the location specified by OPENSTACK_CONFIG_FILE, and extract the string
    # from the key OPENSTACK_CONFIG_DB_KEY, in the section specified by
    # OPENSTACK_CONFIG_DB_SECTION.
    
    import os
    import sys
    try:
        import ConfigParser
        PARSER_OPTS = {}
    except ImportError:
        import configparser as ConfigParser
        PARSER_OPTS = {"strict": False}
    import logging
    from sqlalchemy import create_engine
    
    # Create logger, console handler and formatter
    logger = logging.getLogger('OpenStack-Helm DB Init')
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Set the formatter and add the handler
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    
    
    # Get the connection string for the service db root user
    if "ROOT_DB_CONNECTION" in os.environ:
        db_connection = os.environ['ROOT_DB_CONNECTION']
        logger.info('Got DB root connection')
    else:
        logger.critical('environment variable ROOT_DB_CONNECTION not set')
        sys.exit(1)
    
    mysql_x509 = os.getenv('MARIADB_X509', "")
    ssl_args = {}
    if mysql_x509:
        ssl_args = {'ssl': {'ca': '/etc/mysql/certs/ca.crt',
                    'key': '/etc/mysql/certs/tls.key',
                    'cert': '/etc/mysql/certs/tls.crt'}}
    
    # Get the connection string for the service db
    if "OPENSTACK_CONFIG_FILE" in os.environ:
        os_conf = os.environ['OPENSTACK_CONFIG_FILE']
        if "OPENSTACK_CONFIG_DB_SECTION" in os.environ:
            os_conf_section = os.environ['OPENSTACK_CONFIG_DB_SECTION']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_SECTION not set')
            sys.exit(1)
        if "OPENSTACK_CONFIG_DB_KEY" in os.environ:
            os_conf_key = os.environ['OPENSTACK_CONFIG_DB_KEY']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_KEY not set')
            sys.exit(1)
        try:
            config = ConfigParser.RawConfigParser(**PARSER_OPTS)
            logger.info("Using {0} as db config source".format(os_conf))
            config.read(os_conf)
            logger.info("Trying to load db config from {0}:{1}".format(
                os_conf_section, os_conf_key))
            user_db_conn = config.get(os_conf_section, os_conf_key)
            logger.info("Got config from {0}".format(os_conf))
        except:
            logger.critical("Tried to load config from {0} but failed.".format(os_conf))
            raise
    elif "DB_CONNECTION" in os.environ:
        user_db_conn = os.environ['DB_CONNECTION']
        logger.info('Got config from DB_CONNECTION env var')
    else:
        logger.critical('Could not get db config, either from config file or env var')
        sys.exit(1)
    
    # Root DB engine
    try:
        root_engine_full = create_engine(db_connection)
        root_user = root_engine_full.url.username
        root_password = root_engine_full.url.password
        drivername = root_engine_full.url.drivername
        host = root_engine_full.url.host
        port = root_engine_full.url.port
        root_engine_url = ''.join([drivername, '://', root_user, ':', root_password, '@', host, ':', str (port)])
        root_engine = create_engine(root_engine_url, connect_args=ssl_args)
        connection = root_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1} as {2}".format(
            host, port, root_user))
    except:
        logger.critical('Could not connect to database as root user')
        raise
    
    # User DB engine
    try:
        user_engine = create_engine(user_db_conn, connect_args=ssl_args)
        # Get our user data out of the user_engine
        database = user_engine.url.database
        user = user_engine.url.username
        password = user_engine.url.password
        logger.info('Got user db config')
    except:
        logger.critical('Could not get user database config')
        raise
    
    # Create DB
    try:
        root_engine.execute("CREATE DATABASE IF NOT EXISTS {0}".format(database))
        logger.info("Created database {0}".format(database))
    except:
        logger.critical("Could not create database {0}".format(database))
        raise
    
    # Create DB User
    try:
        root_engine.execute(
            "GRANT ALL ON `{0}`.* TO \'{1}\'@\'%%\' IDENTIFIED BY \'{2}\' {3}".format(
                database, user, password, mysql_x509))
        logger.info("Created user {0} for {1}".format(user, database))
    except:
        logger.critical("Could not create user {0} for {1}".format(user, database))
        raise
    
    # Test connection
    try:
        connection = user_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1}/{2} as {3}".format(
            host, port, database, user))
    except:
        logger.critical('Could not connect to database as user')
        raise
    
    logger.info('Finished DB Management')
  db-sync.sh: |
    #!/bin/bash
    
    
    
    set -ex
    exec alembic --config /etc/workloadmgr/workloadmgr.conf upgrade head
  db-drop.py: |    
    #!/usr/bin/env python
    
    # Drops db and user for an OpenStack Service:
    # Set ROOT_DB_CONNECTION and DB_CONNECTION environment variables to contain
    # SQLAlchemy strings for the root connection to the database and the one you
    # wish the service to use. Alternatively, you can use an ini formatted config
    # at the location specified by OPENSTACK_CONFIG_FILE, and extract the string
    # from the key OPENSTACK_CONFIG_DB_KEY, in the section specified by
    # OPENSTACK_CONFIG_DB_SECTION.
    
    import os
    import sys
    try:
        import ConfigParser
        PARSER_OPTS = {}
    except ImportError:
        import configparser as ConfigParser
        PARSER_OPTS = {"strict": False}
    import logging
    from sqlalchemy import create_engine
    
    # Create logger, console handler and formatter
    logger = logging.getLogger('OpenStack-Helm DB Drop')
    logger.setLevel(logging.DEBUG)
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Set the formatter and add the handler
    ch.setFormatter(formatter)
    logger.addHandler(ch)
    
    
    # Get the connection string for the service db root user
    if "ROOT_DB_CONNECTION" in os.environ:
        db_connection = os.environ['ROOT_DB_CONNECTION']
        logger.info('Got DB root connection')
    else:
        logger.critical('environment variable ROOT_DB_CONNECTION not set')
        sys.exit(1)
    
    mysql_x509 = os.getenv('MARIADB_X509', "")
    ssl_args = {}
    if mysql_x509:
        ssl_args = {'ssl': {'ca': '/etc/mysql/certs/ca.crt',
                            'key': '/etc/mysql/certs/tls.key',
                            'cert': '/etc/mysql/certs/tls.crt'}}
    
    # Get the connection string for the service db
    if "OPENSTACK_CONFIG_FILE" in os.environ:
        os_conf = os.environ['OPENSTACK_CONFIG_FILE']
        if "OPENSTACK_CONFIG_DB_SECTION" in os.environ:
            os_conf_section = os.environ['OPENSTACK_CONFIG_DB_SECTION']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_SECTION not set')
            sys.exit(1)
        if "OPENSTACK_CONFIG_DB_KEY" in os.environ:
            os_conf_key = os.environ['OPENSTACK_CONFIG_DB_KEY']
        else:
            logger.critical('environment variable OPENSTACK_CONFIG_DB_KEY not set')
            sys.exit(1)
        try:
            config = ConfigParser.RawConfigParser(**PARSER_OPTS)
            logger.info("Using {0} as db config source".format(os_conf))
            config.read(os_conf)
            logger.info("Trying to load db config from {0}:{1}".format(
                os_conf_section, os_conf_key))
            user_db_conn = config.get(os_conf_section, os_conf_key)
            logger.info("Got config from {0}".format(os_conf))
        except:
            logger.critical("Tried to load config from {0} but failed.".format(os_conf))
            raise
    elif "DB_CONNECTION" in os.environ:
        user_db_conn = os.environ['DB_CONNECTION']
        logger.info('Got config from DB_CONNECTION env var')
    else:
        logger.critical('Could not get db config, either from config file or env var')
        sys.exit(1)
    
    # Root DB engine
    try:
        root_engine_full = create_engine(db_connection)
        root_user = root_engine_full.url.username
        root_password = root_engine_full.url.password
        drivername = root_engine_full.url.drivername
        host = root_engine_full.url.host
        port = root_engine_full.url.port
        root_engine_url = ''.join([drivername, '://', root_user, ':', root_password, '@', host, ':', str (port)])
        root_engine = create_engine(root_engine_url, connect_args=ssl_args)
        connection = root_engine.connect()
        connection.close()
        logger.info("Tested connection to DB @ {0}:{1} as {2}".format(
            host, port, root_user))
    except:
        logger.critical('Could not connect to database as root user')
        raise
    
    # User DB engine
    try:
        user_engine = create_engine(user_db_conn, connect_args=ssl_args)
        # Get our user data out of the user_engine
        database = user_engine.url.database
        user = user_engine.url.username
        password = user_engine.url.password
        logger.info('Got user db config')
    except:
        logger.critical('Could not get user database config')
        raise
    
    # Delete DB
    try:
        root_engine.execute("DROP DATABASE IF EXISTS {0}".format(database))
        logger.info("Deleted database {0}".format(database))
    except:
        logger.critical("Could not drop database {0}".format(database))
        raise
    
    # Delete DB User
    try:
        root_engine.execute("DROP USER IF EXISTS {0}".format(user))
        logger.info("Deleted user {0}".format(user))
    except:
        logger.critical("Could not delete user {0}".format(user))
        raise
    
    logger.info('Finished DB Management')
  triliovault-wlm-init.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    # Service boilerplate description
    OS_SERVICE_DESC="${OS_REGION_NAME}: ${OS_SERVICE_NAME} (${OS_SERVICE_TYPE}) service"
    
    # Get Service ID if it exists
    unset OS_SERVICE_ID
    
    # If OS_SERVICE_ID is blank then wait a few seconds to give it
    # additional time and try again
    
    ## INPUT:
    # CLOUD_ADMIN_USER_NAME
    # CLOUD_ADMIN_PROJECT_NAME
    # CLOUD_ADMIN_DOMAIN_NAME
    
    
    CLOUD_ADMIN_USER_NAME=""
    CLOUD_ADMIN_PROJECT_NAME=""
    CLOUD_ADMIN_DOMAIN_NAME=""
    WLM_USER_NAME="triliovault"
    
    # If we have reached this point and a Service ID was not found,
    # then create the service
    OS_SERVICE_ID=$(openstack service create -f value -c id \
                    --name="${OS_SERVICE_NAME}" \
                    --description "${OS_SERVICE_DESC}" \
                    --enable \
                    "${OS_SERVICE_TYPE}")
    
    CLOUD_ADMIN_USER_ID=$(openstack user show -f value -c id \
                    "${CLOUD_ADMIN_USER_NAME}")
    
    CLOUD_ADMIN_DOMAIN_ID=$(openstack domain show -f value -c id \
                    "${CLOUD_ADMIN_DOMAIN_NAME}")
    
    CLOUD_ADMIN_PROJECT_ID=$(openstack project show -f value -c id \
                    "${CLOUD_ADMIN_PROJECT_NAME}")
    
    WLM_USER_ID=$(openstack user show -f value -c id \
                    "${WLM_USER_NAME}")
    
    WLM_USER_DOMAIN_ID=$(openstack user show -f value -c domain_id \
                    "${CLOUD_ADMIN_USER_NAME}")
    
    
    
    
    tee > /tmp/pod-shared-${POD_NAME}/triliovault-wlm-ids.conf << EOF
    [DEFAULT]
    cloud_admin_user_id = $CLOUD_ADMIN_USER_ID
    cloud_admin_domain = $CLOUD_ADMIN_DOMAIN_ID
    cloud_admin_project_id = $CLOUD_ADMIN_PROJECT_ID
    cloud_unique_id = $WLM_USER_ID
    triliovault_user_domain_id = $WLM_USER_DOMAIN_ID
    EOF
    
  triliovault-wlm-api.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    COMMAND="${@:-start}"
    
    function start () {
      exec /usr/bin/python3 /usr/bin/workloadmgr-api \
           --config-file=/etc/triliovault-wlm/triliovault-wlm.conf \
           --config-file=/tmp/pod-shared-triliovault-wlm-api/triliovault-wlm-ids.conf
    }
    
    function stop () {
      kill -TERM 1
    }
    
    $COMMAND
    
  triliovault-wlm-cron.sh: |
    #!/bin/bash
    
    
    
    set -ex
    COMMAND="${@:-start}"
    
    function start () {
      exec /usr/bin/python3 /usr/bin/workloadmgr-cron \
           --config-file=/etc/triliovault-wlm/triliovault-wlm.conf \
           --config-file=/tmp/pod-shared-triliovault-wlm-cron/triliovault-wlm-ids.conf
    }
    
    function stop () {
      kill -TERM 1
    }
    
    $COMMAND
    
    
  triliovault-wlm-scheduler.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    COMMAND="${@:-start}"
    
    function start () {
      exec /usr/bin/python3 /usr/bin/workloadmgr-scheduler \
           --config-file=/etc/triliovault-wlm/triliovault-wlm.conf \
           --config-file=/tmp/pod-shared-triliovault-wlm-scheduler/triliovault-wlm-ids.conf
    }
    
    function stop () {
      kill -TERM 1
    }
    
    $COMMAND
    
  triliovault-wlm-workloads.sh: |
    #!/bin/bash
    
    
    
    set -ex
    
    
    
    
    COMMAND="${@:-start}"
    
    function start () {
    
      
    
    
      # Start workloadmgr workloads service
      /usr/bin/python3 /usr/bin/workloadmgr-workloads \
         --config-file=/etc/triliovault-wlm/triliovault-wlm.conf \
         --config-file=/tmp/pod-shared-triliovault-wlm-workloads/triliovault-wlm-ids.conf &
    
      status=$?
      if [ $status -ne 0 ]; then
        echo "Failed to start tvault contego service: $status"
        exit $status
      fi
    }
    
    function stop () {
      kill -TERM 1
    }
    
    
  ks-service.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    # Service boilerplate description
    OS_SERVICE_DESC="${OS_REGION_NAME}: ${OS_SERVICE_NAME} (${OS_SERVICE_TYPE}) service"
    
    # Get Service ID if it exists
    unset OS_SERVICE_ID
    
    # FIXME - There seems to be an issue once in a while where the
    # openstack service list fails and encounters an error message such as:
    #   Unable to establish connection to
    #   https://keystone-api.openstack.svc.cluster.local:5000/v3/auth/tokens:
    #   ('Connection aborted.', OSError("(104, 'ECONNRESET')",))
    # During an upgrade scenario, this would cause the OS_SERVICE_ID to be blank
    # and it would attempt to create a new service when it was not needed.
    # This duplciate service would sometimes be used by other services such as
    # Horizon and would give an 'Invalid Service Catalog' error.
    # This loop allows for a 'retry' of the openstack service list in an
    # attempt to get the service list as expected if it does ecounter an error.
    # This loop and recheck can be reverted once the underlying issue is addressed.
    
    # If OS_SERVICE_ID is blank then wait a few seconds to give it
    # additional time and try again
    for i in $(seq 3)
    do
      OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                       grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                       sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )
    
      # If the service was found, go ahead and exit successfully.
      if [[ -n "${OS_SERVICE_ID}" ]]; then
        exit 0
      fi
    
      sleep 2
    done
    
    # If we've reached this point and a Service ID was not found,
    # then create the service
    OS_SERVICE_ID=$(openstack service create -f value -c id \
                    --name="${OS_SERVICE_NAME}" \
                    --description "${OS_SERVICE_DESC}" \
                    --enable \
                    "${OS_SERVICE_TYPE}")
  ks-endpoints.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    # Get Service ID
    OS_SERVICE_ID=$( openstack service list -f csv --quote none | \
                      grep ",${OS_SERVICE_NAME},${OS_SERVICE_TYPE}$" | \
                        sed -e "s/,${OS_SERVICE_NAME},${OS_SERVICE_TYPE}//g" )
    
    # Get Endpoint ID if it exists
    OS_ENDPOINT_ID=$( openstack endpoint list  -f csv --quote none | \
                      grep "^[a-z0-9]*,${OS_REGION_NAME},${OS_SERVICE_NAME},${OS_SERVICE_TYPE},True,${OS_SVC_ENDPOINT}," | \
                      awk -F ',' '{ print $1 }' )
    
    # Making sure only a single endpoint exists for a service within a region
    if [ "$(echo $OS_ENDPOINT_ID | wc -w)" -gt "1" ]; then
      echo "More than one endpoint found, cleaning up"
      for ENDPOINT_ID in $OS_ENDPOINT_ID; do
        openstack endpoint delete ${ENDPOINT_ID}
      done
      unset OS_ENDPOINT_ID
    fi
    
    # Determine if Endpoint needs updated
    if [[ ${OS_ENDPOINT_ID} ]]; then
      OS_ENDPOINT_URL_CURRENT=$(openstack endpoint show ${OS_ENDPOINT_ID} -f value -c url)
      if [ "${OS_ENDPOINT_URL_CURRENT}" == "${OS_SERVICE_ENDPOINT}" ]; then
        echo "Endpoints Match: no action required"
        OS_ENDPOINT_UPDATE="False"
      else
        echo "Endpoints Dont Match: removing existing entries"
        openstack endpoint delete ${OS_ENDPOINT_ID}
        OS_ENDPOINT_UPDATE="True"
      fi
    else
      OS_ENDPOINT_UPDATE="True"
    fi
    
    # Update Endpoint if required
    if [[ "${OS_ENDPOINT_UPDATE}" == "True" ]]; then
      OS_ENDPOINT_ID=$( openstack endpoint create -f value -c id \
        --region="${OS_REGION_NAME}" \
        "${OS_SERVICE_ID}" \
        ${OS_SVC_ENDPOINT} \
        "${OS_SERVICE_ENDPOINT}" )
    fi
    
    # Display the Endpoint
    openstack endpoint show ${OS_ENDPOINT_ID}
  ks-user.sh: |    
    #!/bin/bash
    
    # Copyright 2017 Pete Birley
    #
    # Licensed under the Apache License, Version 2.0 (the "License");
    # you may not use this file except in compliance with the License.
    # You may obtain a copy of the License at
    #
    # http://www.apache.org/licenses/LICENSE-2.0
    #
    # Unless required by applicable law or agreed to in writing, software
    # distributed under the License is distributed on an "AS IS" BASIS,
    # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    # See the License for the specific language governing permissions and
    # limitations under the License.
    
    set -ex
    
    shopt -s nocasematch
    
    if [[ "${SERVICE_OS_PROJECT_DOMAIN_NAME}" == "Default" ]]
    then
      PROJECT_DOMAIN_ID="default"
    else
      # Manage project domain
      PROJECT_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}" \
        "${SERVICE_OS_PROJECT_DOMAIN_NAME}")
    fi
    
    if [[ "${SERVICE_OS_USER_DOMAIN_NAME}" == "Default" ]]
    then
      USER_DOMAIN_ID="default"
    else
      # Manage user domain
      USER_DOMAIN_ID=$(openstack domain create --or-show --enable -f value -c id \
        --description="Domain for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}" \
        "${SERVICE_OS_USER_DOMAIN_NAME}")
    fi
    
    shopt -u nocasematch
    
    # Manage user project
    USER_PROJECT_DESC="Service Project for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_PROJECT_DOMAIN_NAME}"
    USER_PROJECT_ID=$(openstack project create --or-show --enable -f value -c id \
        --domain="${PROJECT_DOMAIN_ID}" \
        --description="${USER_PROJECT_DESC}" \
        "${SERVICE_OS_PROJECT_NAME}");
    
    # Manage user
    USER_DESC="Service User for ${SERVICE_OS_REGION_NAME}/${SERVICE_OS_USER_DOMAIN_NAME}/${SERVICE_OS_SERVICE_NAME}"
    USER_ID=$(openstack user create --or-show --enable -f value -c id \
        --domain="${USER_DOMAIN_ID}" \
        --project-domain="${PROJECT_DOMAIN_ID}" \
        --project="${USER_PROJECT_ID}" \
        --description="${USER_DESC}" \
        "${SERVICE_OS_USERNAME}");
    
    # Manage user password (we do this in a seperate step to ensure the password is updated if required)
    set +x
    echo "Setting user password via: openstack user set --password=xxxxxxx ${USER_ID}"
    openstack user set --password="${SERVICE_OS_PASSWORD}" "${USER_ID}"
    set -x
    
    function ks_assign_user_role () {
      if [[ "$SERVICE_OS_ROLE" == "admin" ]]
      then
        USER_ROLE_ID="$SERVICE_OS_ROLE"
      else
        USER_ROLE_ID=$(openstack role create --or-show -f value -c id "${SERVICE_OS_ROLE}");
      fi
    
      # Manage user role assignment
      openstack role add \
          --user="${USER_ID}" \
          --user-domain="${USER_DOMAIN_ID}" \
          --project-domain="${PROJECT_DOMAIN_ID}" \
          --project="${USER_PROJECT_ID}" \
          "${USER_ROLE_ID}"
    }
    
    # Manage user service role
    IFS=','
    for SERVICE_OS_ROLE in ${SERVICE_OS_ROLES}; do
      ks_assign_user_role
    done
    
    # Manage user member role
    : ${MEMBER_OS_ROLE:="member"}
    export USER_ROLE_ID=$(openstack role create --or-show -f value -c id \
        "${MEMBER_OS_ROLE}");
    ks_assign_user_role
  rabbit-init.sh: |    
    #!/bin/bash
    set -e
    # Extract connection details
    RABBIT_HOSTNAME=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $2}' | \
      awk -F'[:/]' '{print $1}')
    RABBIT_PORT=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $2}' | \
      awk -F'[:/]' '{print $2}')
    
    # Extract Admin User creadential
    RABBITMQ_ADMIN_USERNAME=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $4}')
    RABBITMQ_ADMIN_PASSWORD=$(echo "${RABBITMQ_ADMIN_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $5}')
    
    # Extract User creadential
    RABBITMQ_USERNAME=$(echo "${RABBITMQ_USER_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $4}')
    RABBITMQ_PASSWORD=$(echo "${RABBITMQ_USER_CONNECTION}" | \
      awk -F'[@]' '{print $1}' | \
      awk -F'[//:]' '{print $5}')
    
    # Extract User vHost
    RABBITMQ_VHOST=$(echo "${RABBITMQ_USER_CONNECTION}" | \
      awk -F'[@]' '{print $2}' | \
      awk -F'[:/]' '{print $3}')
    # Resolve vHost to / if no value is set
    RABBITMQ_VHOST="${RABBITMQ_VHOST:-/}"
    
    function rabbitmqadmin_cli () {
      if [ -n "$RABBITMQ_X509" ]
      then
        rabbitmqadmin \
          --ssl \
          --ssl-disable-hostname-verification \
          --ssl-ca-cert-file="${USER_CERT_PATH}/ca.crt" \
          --ssl-cert-file="${USER_CERT_PATH}/tls.crt" \
          --ssl-key-file="${USER_CERT_PATH}/tls.key" \
          --host="${RABBIT_HOSTNAME}" \
          --port="${RABBIT_PORT}" \
          --username="${RABBITMQ_ADMIN_USERNAME}" \
          --password="${RABBITMQ_ADMIN_PASSWORD}" \
          ${@}
      else
        rabbitmqadmin \
          --host="${RABBIT_HOSTNAME}" \
          --port="${RABBIT_PORT}" \
          --username="${RABBITMQ_ADMIN_USERNAME}" \
          --password="${RABBITMQ_ADMIN_PASSWORD}" \
          ${@}
      fi
    }
    
    echo "Managing: User: ${RABBITMQ_USERNAME}"
    rabbitmqadmin_cli \
      declare user \
      name="${RABBITMQ_USERNAME}" \
      password="${RABBITMQ_PASSWORD}" \
      tags="user"
    
    if [ "${RABBITMQ_VHOST}" != "/" ]
    then
      echo "Managing: vHost: ${RABBITMQ_VHOST}"
      rabbitmqadmin_cli \
        declare vhost \
        name="${RABBITMQ_VHOST}"
    else
      echo "Skipping root vHost declaration: vHost: ${RABBITMQ_VHOST}"
    fi
    
    echo "Managing: Permissions: ${RABBITMQ_USERNAME} on ${RABBITMQ_VHOST}"
    rabbitmqadmin_cli \
      declare permission \
      vhost="${RABBITMQ_VHOST}" \
      user="${RABBITMQ_USERNAME}" \
      configure=".*" \
      write=".*" \
      read=".*"
    
    if [ ! -z "$RABBITMQ_AUXILIARY_CONFIGURATION" ]
    then
      echo "Applying additional configuration"
      echo "${RABBITMQ_AUXILIARY_CONFIGURATION}" > /tmp/rmq_definitions.json
      rabbitmqadmin_cli import /tmp/rmq_definitions.json
    fi

---
# Source: triliovault/templates/nfs-pv.yaml


---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: triliovault-nfs-pv-192-168-122-101-opt-share1
  labels:
    release_group: release-name
    application: triliovault
    component: datamover
spec:
  capacity:
    storage: 20Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs
  mountOptions: 
    - nolock
    - soft
    - vers=3
    - timeo=180
    - intr
    - lookupcache=none
    
  nfs:
    path: /opt/share1
    server: 192.168.122.101
---
# Source: triliovault/templates/nfs-pvc.yaml


---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: triliovault-nfs-pvc-192-168-122-101-opt-share1
    release_group: release-name
    application: triliovault
    component: datamover
spec:
  storageClassName: nfs
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 20Gi
---
# Source: triliovault/templates/daemonset-datamover.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-datamover
  namespace: default

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: triliovault-datamover-openstack-compute-node
  annotations:
    "openstackhelm.openstack.org/release_uuid": ""
  labels:
    release_group: release-name
    application: triliovault
    component: datamover
spec:
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault
      component: datamover
  
  minReadySeconds: 0
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault
        component: datamover
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
        configmap-bin-hash: "74a27b603de0766dc35bb1056f04932ffa291bf59a277e58855e309de08441ff"
        configmap-etc-hash: "06e35fa7d6fd0c3ae9997e3834b4a65284c523833850ee435a00603f6c789aed"
    spec:
      serviceAccountName: triliovault-datamover
      securityContext:
        runAsUser: 42424
        
      affinity:
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: release_group
                    operator: In
                    values:
                    - release-name
                  - key: application
                    operator: In
                    values:
                    - triliovault
                  - key: component
                    operator: In
                    values:
                    - datamover
                  
              topologyKey: kubernetes.io/hostname
            weight: 10
      hostNetwork: true
      hostPID: true
      hostIPC: true
      dnsPolicy: ClusterFirstWithHostNet
      nodeSelector:
        openstack-compute-node: enabled
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: ""
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            null
            
      containers:
        - name: triliovault-datamover
          image: "docker.io/trilio/triliovault-datamover-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          
          securityContext:
            privileged: true
            runAsUser: 0
            
          command:
            - /tmp/triliovault-datamover.sh
            - start
          lifecycle:
            preStop:
              exec:
                command:
                  - /tmp/triliovault-datamover.sh
                  - stop
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: vartrilio
              mountPath: /var/trilio
            - name: triliovault-datamover-etc
              mountPath: /etc/triliovault-datamover/triliovault-datamover.conf
              subPath: triliovault-datamover.conf
              readOnly: true
            - mountPath: /etc/triliovault-object-store/triliovault-object-store.conf
              name: triliovault-datamover-etc
              readOnly: true
              subPath: triliovault-object-store.conf
            - mountPath: /etc/fuse.conf
              name: triliovault-datamover-etc
              readOnly: true
              subPath: fuse.conf
            - mountPath: /etc/triliovault-datamover/s3-cert.pem
              name: triliovault-datamover-etc
              readOnly: true
              subPath: s3-cert.pem
            - name: triliovault-datamover-bin
              mountPath: /tmp/triliovault-datamover.sh
              subPath: triliovault-datamover.sh
              readOnly: true
            - name: varlibnova
              mountPath: /var/lib/nova
            - name: varliblibvirt
              mountPath: /var/lib/libvirt
            - name: run
              mountPath: /run
            - name: cgroup
              mountPath: /sys/fs/cgroup
            - name: machine-id
              mountPath: /etc/machine-id
              readOnly: true
            - name: nova-etc
              mountPath: /etc/nova/nova.conf
              subPath: nova-compute.conf
              readOnly: true
            - name: nova-etc
              mountPath: /etc/nova/api-paste.ini
              subPath: api-paste.ini
              readOnly: true
            - name: triliovault-datamover-etc
              mountPath: /etc/triliovault-datamover/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: nova-etc
              mountPath: /etc/triliovault-datamover/policy.yaml
              subPath: policy.yaml
              readOnly: true
            - name: etcceph
              mountPath: /etc/ceph
              mountPropagation: Bidirectional
            - name: dev
              mountPath: /dev
              mountPropagation: HostToContainer
            - name: etciscsi
              mountPath: /etc/iscsi
              mountPropagation: HostToContainer
            - mountPath: /lib/modules
              name: libmodules
              readOnly: true
            - name: nova-bin
              mountPath: /usr/local/sbin/multipath
              subPath: multipath
            - name: nova-bin
              mountPath: /usr/local/sbin/multipathd
              subPath: multipathd
            - name: etcmultipath
              mountPath: /etc/multipath
              mountPropagation: Bidirectional
            - name: triliovault-nfs-pv-192-168-122-101-opt-share1
              mountPath: "/var/trilio/triliovault-mounts/LW9wdC1zaGFyZTE="            
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: triliovault-datamover-tls-api
              mountPath: /etc/triliovault_datamover/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: triliovault-datamover-tls-api
              mountPath: /etc/triliovault_datamover/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: triliovault-datamover-tls-api
              mountPath: /etc/triliovault_datamover/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/ca.crt
              subPath: ca.crt
              readOnly: true

      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: vartrilio
          hostPath:
            path: /var/trilio
        - name: triliovault-datamover-etc
          secret:
            secretName: triliovault-datamover-etc
            defaultMode: 0444
        - name: triliovault-datamover-bin
          configMap:
            name: triliovault-datamover-bin
            defaultMode: 0555
        - name: varlibnova
          hostPath:
            path: /var/lib/nova
        - name: varliblibvirt
          hostPath:
            path: /var/lib/libvirt
        - name: run
          hostPath:
            path: /run
        - name: cgroup
          hostPath:
            path: /sys/fs/cgroup
        - name: machine-id
          hostPath:
            path: /etc/machine-id
        - name: nova-bin
          configMap:
            name: nova-bin
            defaultMode: 0555
        - name: nova-etc
          secret:
            secretName: nova-etc
            defaultMode: 0444
        - name: etcceph
          hostPath:
            path: /var/lib/openstack-helm/compute/nova
        - name: libmodules
          hostPath:
            path: /lib/modules
        - name: dev
          hostPath:
            path: /dev
        - name: etciscsi
          hostPath:
            path: /etc/iscsi
        - name: triliovault-nfs-pv-192-168-122-101-opt-share1
          persistentVolumeClaim:
            claimName: triliovault-nfs-pvc-192-168-122-101-opt-share1        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292        
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292


---
# Source: triliovault/templates/deployment-datamover-api.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-datamover-api
  namespace: default
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triliovault-datamover-api
  annotations:
    "openstackhelm.openstack.org/release_uuid": ""
  labels:
    release_group: release-name
    application: triliovault
    component: datamover-api
spec:
  replicas: 3
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault
      component: datamover-pi
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 3
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault
        component: datamover-api
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
        configmap-bin-hash: "74a27b603de0766dc35bb1056f04932ffa291bf59a277e58855e309de08441ff"
        configmap-etc-hash: "06e35fa7d6fd0c3ae9997e3834b4a65284c523833850ee435a00603f6c789aed"
    spec:
      serviceAccountName: triliovault-datamover-api
      securityContext:
        runAsUser: 42424
        
      affinity:
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: release_group
                    operator: In
                    values:
                    - release-name
                  - key: application
                    operator: In
                    values:
                    - triliovault
                  - key: component
                    operator: In
                    values:
                    - datamover-api
                  
              topologyKey: kubernetes.io/hostname
            weight: 10
      nodeSelector:
        openstack-control-plane: enabled
      terminationGracePeriodSeconds: 30
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: ",default:keystone-api"
            - name: DEPENDENCY_JOBS
              value: "triliovault-db-sync,triliovault-ks-user,triliovault-ks-endpoints"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            null
            
        - name: triliovault-datamover-api-init
          image: "docker.io/trilio/triliovault-datamover-api-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          command:
            - /tmp/triliovault-datamover-api-init.sh
          terminationMessagePath: /var/log/termination-log
          volumeMounts:
            - name: triliovault-datamover-bin
              mountPath: /tmp/triliovault-datamover-api-init.sh
              subPath: triliovault-datamover-api-init.sh
              readOnly: true
            - name: pod-shared-triliovault-datamover-api
              mountPath: /tmp/pod-shared-triliovault-datamover-api

      containers:
        - name: triliovault-datamover-api
          image: "docker.io/trilio/triliovault-datamover-api-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          
          securityContext:
            readOnlyRootFilesystem: false
            runAsUser: 0
            
          command:
            - /tmp/triliovault-datamover-api.sh
            - start
          lifecycle:
            preStop:
              exec:
                command:
                  - /tmp/triliovault-datamover-api.sh
                  - stop
          ports:
            - name: d-api
              containerPort: 8784
          readinessProbe:
            tcpSocket:
              port: 8784
          livenessProbe:
            tcpSocket:
              port: 8784
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: triliovault-datamover-etc
              mountPath: /etc/triliovault-datamover/triliovault-datamover-api.conf
              subPath: triliovault-datamover-api.conf
              readOnly: true
            - name: triliovault-datamover-etc
              mountPath: /etc/triliovault-datamover/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: triliovault-datamover-bin
              mountPath: /tmp/triliovault-datamover-api.sh
              subPath: triliovault-datamover-api.sh
              readOnly: true
            - name: pod-shared-triliovault-datamover-api
              mountPath: /tmp/pod-shared-triliovault-datamover-api            
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: triliovault-datamover-tls-api
              mountPath: /etc/triliovault_datamover/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: triliovault-datamover-tls-api
              mountPath: /etc/triliovault_datamover/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: triliovault-datamover-tls-api
              mountPath: /etc/triliovault_datamover/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/ca.crt
              subPath: ca.crt
              readOnly: true

      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: triliovault-datamover-etc
          secret:
            secretName: triliovault-datamover-etc
            defaultMode: 0444
        - name: triliovault-datamover-bin
          configMap:
            name: triliovault-datamover-bin
            defaultMode: 0555
	- name: pod-shared-triliovault-datamover-api
          emptyDir: {}        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292        
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292


---
# Source: triliovault/templates/deployment-wlm-api.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-api
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-api
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-api
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-api
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-api
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triliovault-wlm-api
  annotations:
    "openstackhelm.openstack.org/release_uuid": ""
  labels:
    release_group: release-name
    application: triliovault
    component: wlm-api
spec:
  replicas: 3
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault
      component: wlm-api
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 3
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault
        component: wlm-api
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
        configmap-bin-hash: "13be332d37acef23b68cadb2aa415eb76eacd1b5366e284654ad8d6fc8ccceb1"
        configmap-etc-hash: "eeaa3c3cccde53f5ede6b44e1eecb198c540514304fd23af6178eaeccc8a8bca"
    spec:
      serviceAccountName: triliovault-wlm-api
      securityContext:
        runAsUser: 42424
        
      affinity:
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: release_group
                    operator: In
                    values:
                    - release-name
                  - key: application
                    operator: In
                    values:
                    - triliovault
                  - key: component
                    operator: In
                    values:
                    - wlm_api
                  
              topologyKey: kubernetes.io/hostname
            weight: 10
      nodeSelector:
        openstack-control-plane: enabled
      terminationGracePeriodSeconds: 30
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: ",default:keystone-api"
            - name: DEPENDENCY_JOBS
              value: "triliovault-db-sync,triliovault-ks-user,triliovault-ks-endpoints"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            null
            
        - name: triliovault-wlm-api-init
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          env:
            - name: POD_NAME
              value: "triliovault-wlm-api"
          command:
            - /tmp/triliovault-wlm-api-init.sh
          terminationMessagePath: /var/log/termination-log
          volumeMounts:
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-api-init.sh
              subPath: triliovault-wlm-init.sh
              readOnly: true
            - name: pod-shared-triliovault-wlm-api
              mountPath: /tmp/pod-shared-triliovault-wlm-api
      containers:
        - name: triliovault-wlm-api
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          
          securityContext:
            allowPrivilegeEscalation: true
            privileged: true
            readOnlyRootFilesystem: false
            runAsUser: 0
            
          command:
            - /tmp/triliovault-wlm-api.sh
            - start
          lifecycle:
            preStop:
              exec:
                command:
                  - /tmp/triliovault-wlm-api.sh
                  - stop
          ports:
            - name: w-api
              containerPort: 8780
          readinessProbe:
            tcpSocket:
              port: 8780
          livenessProbe:
            tcpSocket:
              port: 8780
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: trilio-mounts
              mountPath: /var/triliovault-mounts
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/triliovault-wlm.conf
              subPath: triliovault-wlm.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/api-paste.ini
              subPath: api-paste.ini
              readOnly: true
            - mountPath: /etc/triliovault-object-store/triliovault-object-store.conf
              name: triliovault-wlm-etc
              readOnly: true
              subPath: triliovault-object-store.conf
            - mountPath: /etc/fuse.conf
              name: triliovault-wlm-etc
              readOnly: true
              subPath: fuse.conf
            - mountPath: /etc/triliovault-wlm/s3-cert.pem
              name: triliovault-wlm-etc
              readOnly: true
              subPath: s3-cert.pem
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-api.sh
              subPath: wlm.sh
              readOnly: true
            - name: pod-shared-triliovault-wlm-api
              mountPath: /tmp/pod-shared-triliovault-wlm-api            
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/ca.crt
              subPath: ca.crt
              readOnly: true

      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: trilio-mounts
          emptyDir: {}
        - name: triliovault-wlm-etc
          secret:
            secretName: triliovault-wlm-etc
            defaultMode: 0444
        - name: triliovault-wlm-bin
          configMap:
            name: triliovault-wlm-bin
            defaultMode: 0555
	      - name: pod-shared-triliovault-wlm-api
          emptyDir: {}        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292        
        - name: triliovault-wlm-tls-api
          secret:
            secretName: triliovault-wlm-tls-api
            defaultMode: 292        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292


---
# Source: triliovault/templates/deployment-wlm-cron.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-cron
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-cron
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-cron
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-cron
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-cron
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triliovault-wlm-cron
  annotations:
    "openstackhelm.openstack.org/release_uuid": ""
  labels:
    release_group: release-name
    application: triliovault
    component: wlm-cron
spec:
  replicas: 1
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault
      component: wlm-cron
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 3
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault
        component: wlm-cron
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
        configmap-bin-hash: "13be332d37acef23b68cadb2aa415eb76eacd1b5366e284654ad8d6fc8ccceb1"
        configmap-etc-hash: "eeaa3c3cccde53f5ede6b44e1eecb198c540514304fd23af6178eaeccc8a8bca"
    spec:
      serviceAccountName: triliovault-wlm-cron
      securityContext:
        runAsUser: 42424
        
      affinity:
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: release_group
                    operator: In
                    values:
                    - release-name
                  - key: application
                    operator: In
                    values:
                    - triliovault
                  - key: component
                    operator: In
                    values:
                    - api
                  
              topologyKey: kubernetes.io/hostname
            weight: 10
      nodeSelector:
        openstack-control-plane: enabled
      terminationGracePeriodSeconds: 30
      hostPID: true
      hostIPC: true
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:triliovault-wlm-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            null
            
        - name: triliovault-wlm-cron-init
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          env:
            - name: POD_NAME
              value: "triliovault-wlm-cron"
          command:
            - /tmp/triliovault-wlm-cron-init.sh
          terminationMessagePath: /var/log/termination-log
          volumeMounts:
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-cron-init.sh
              subPath: triliovault-wlm-init.sh
              readOnly: true
            - name: pod-shared-triliovault-wlm-cron
              mountPath: /tmp/pod-shared-triliovault-wlm-cron
      containers:
        - name: triliovault-wlm-cron
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          
          securityContext:
            allowPrivilegeEscalation: true
            privileged: true
            readOnlyRootFilesystem: true
            runAsUser: 0
            
          command:
            - /tmp/triliovault-wlm-cron.sh
            - start
          lifecycle:
            preStop:
              exec:
                command:
                  - /tmp/triliovault-wlm-cron.sh
                  - stop
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/triliovault-wlm.conf
              subPath: triliovault-wlm.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/api-paste.ini
              subPath: api-paste.ini
              readOnly: true
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-cron.sh
              subPath: triliovault-wlm-cron.sh
              readOnly: true
            - name: pod-shared-triliovault-wlm-cron
              mountPath: /tmp/pod-shared-triliovault-wlm-cron            
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/ca.crt
              subPath: ca.crt
              readOnly: true

      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: triliovault-wlm-etc
          secret:
            secretName: triliovault-wlm-etc
            defaultMode: 0444
        - name: triliovault-wlm-bin
          configMap:
            name: triliovault-wlm-bin
            defaultMode: 0555
	      - name: pod-shared-triliovault-wlm-cron
          emptyDir: {}        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292        
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292


---
# Source: triliovault/templates/deployment-wlm-scheduler.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-scheduler
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-scheduler
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-scheduler
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-scheduler
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-scheduler
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triliovault-wlm-scheduler
  annotations:
    "openstackhelm.openstack.org/release_uuid": ""
  labels:
    release_group: release-name
    application: triliovault
    component: wlm-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault
      component: wlm-scheduler
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 3
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault
        component: wlm-scheduler
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
        configmap-bin-hash: "13be332d37acef23b68cadb2aa415eb76eacd1b5366e284654ad8d6fc8ccceb1"
        configmap-etc-hash: "eeaa3c3cccde53f5ede6b44e1eecb198c540514304fd23af6178eaeccc8a8bca"
    spec:
      serviceAccountName: triliovault-wlm-scheduler
      securityContext:
        runAsUser: 42424
        
      affinity:
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: release_group
                    operator: In
                    values:
                    - release-name
                  - key: application
                    operator: In
                    values:
                    - triliovault
                  - key: component
                    operator: In
                    values:
                    - wlm-scheduler
                  
              topologyKey: kubernetes.io/hostname
            weight: 10
      nodeSelector:
        openstack-control-plane: enabled
      terminationGracePeriodSeconds: 30
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:triliovault-wlm-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            null
            
        - name: triliovault-wlm-scheduler-init
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          env:
            - name: POD_NAME
              value: "triliovault-wlm-scheduler"
          command:
            - /tmp/triliovault-wlm-scheduler-init.sh
          terminationMessagePath: /var/log/termination-log
          volumeMounts:
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-scheduler-init.sh
              subPath: triliovault-wlm-init.sh
              readOnly: true
            - name: pod-shared-triliovault-wlm-scheduler
              mountPath: /tmp/pod-shared-triliovault-wlm-scheduler
      containers:
        - name: triliovault-wlm-scheduler
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 64060
            
          command:
            - /tmp/triliovault-wlm-scheduler.sh
            - start
          lifecycle:
            preStop:
              exec:
                command:
                  - /tmp/triliovault-wlm-scheduler.sh
                  - stop
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: trilio-mounts
              mountPath: /var/triliovault-mounts
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/triliovault-wlm.conf
              subPath: triliovault-wlm.conf
              readOnly: true
            - name: triliovault-etc
              mountPath: /etc/triliovault-wlm/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/api-paste.ini
              subPath: api-paste.ini
              readOnly: true
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-scheduler.sh
              subPath: triliovault-wlm-scheduler.sh
              readOnly: true
            - name: pod-shared-triliovault-wlm-scheduler
              mountPath: /tmp/pod-shared-triliovault-wlm-scheduler        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292        
        - name: triliovault-wlm-tls-api
          secret:
            secretName: triliovault-wlm-tls-api
            defaultMode: 292        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292

      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: trilio-mounts
          emptyDir: {}
        - name: triliovault-wlm-etc
          secret:
            secretName: triliovault-wlm-etc
            defaultMode: 0444
        - name: triliovault-wlm-bin
          configMap:
            name: triliovault-wlm-bin
            defaultMode: 0555
	      - name: pod-shared-triliovault-wlm-scheduler
          emptyDir: {}        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292        
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292


---
# Source: triliovault/templates/deployment-wlm-workloads.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-workloads
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-workloads
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-workloads
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-workloads
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-workloads
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: triliovault-wlm-workloads
  annotations:
    "openstackhelm.openstack.org/release_uuid": ""
  labels:
    release_group: release-name
    application: triliovault
    component: wlm-workloads
spec:
  replicas: 3
  selector:
    matchLabels:
      release_group: release-name
      application: triliovault
      component: wlm-workloads
  revisionHistoryLimit: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 3
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault
        component: wlm-workloads
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
        configmap-bin-hash: "13be332d37acef23b68cadb2aa415eb76eacd1b5366e284654ad8d6fc8ccceb1"
        configmap-etc-hash: "eeaa3c3cccde53f5ede6b44e1eecb198c540514304fd23af6178eaeccc8a8bca"
    spec:
      serviceAccountName: triliovault-wlm-workloads
      securityContext:
        runAsUser: 42424
        
      affinity:
        
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: release_group
                    operator: In
                    values:
                    - release-name
                  - key: application
                    operator: In
                    values:
                    - triliovault
                  - key: component
                    operator: In
                    values:
                    - wlm-workloads
                  
              topologyKey: kubernetes.io/hostname
            weight: 10
      nodeSelector:
        openstack-control-plane: enabled
      terminationGracePeriodSeconds: 30
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:triliovault-wlm-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            null
            
        - name: triliovault-wlm-workloads-init
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          env:
            - name: POD_NAME
              value: "triliovault-wlm-workloads"
          command:
            - /tmp/triliovault-wlm-workloads-init.sh
          terminationMessagePath: /var/log/termination-log
          volumeMounts:
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-workloads-init.sh
              subPath: triliovault-wlm-init.sh
              readOnly: true
            - name: pod-shared-triliovault-wlm-workloads
              mountPath: /tmp/pod-shared-triliovault-wlm-workloads
      containers:
        - name: triliovault-wlm-workloads
          image: "docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic"
          imagePullPolicy: IfNotPresent
          
          
          securityContext:
            allowPrivilegeEscalation: true
            privileged: true
            readOnlyRootFilesystem: false
            runAsUser: 0
            
          command:
            - /tmp/triliovault-wlm-workloads.sh
            - start
          lifecycle:
            preStop:
              exec:
                command:
                  - /tmp/triliovault-wlm-workloads.sh
                  - stop
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: vartrilio
              mountPath: /var/trilio/
            - name: triliovault-wlm-etc
              mountPath: /etc/workloadmgr/workloadmgr.conf
              subPath: triliovault-wlm.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/triliovault-wlm.conf
              subPath: triliovault-wlm.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/logging.conf
              subPath: logging.conf
              readOnly: true
            - name: triliovault-wlm-etc
              mountPath: /etc/triliovault-wlm/api-paste.ini
              subPath: api-paste.ini
              readOnly: true
            - mountPath: /etc/triliovault-object-store/triliovault-object-store.conf
              name: triliovault-wlm-etc
              readOnly: true
              subPath: tvostore.conf
            - mountPath: /etc/fuse.conf
              name: triliovault-wlm-etc
              readOnly: true
              subPath: fuse.conf
            - mountPath: /etc/triliovault-wlm/s3-cert.pem
              name: triliovault-wlm-etc
              readOnly: true
              subPath: s3-cert.pem
            - name: triliovault-wlm-bin
              mountPath: /tmp/triliovault-wlm-workloads.sh
              subPath: triliovault-wlm-workloads.sh
              readOnly: true
            - name: triliovault-nfs-pv--
              mountPath: ""
            - name: pod-shared-triliovault-wlm-workloads
              mountPath: /tmp/pod-shared-triliovault-wlm-workloads            
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: triliovault-wlm-tls-api
              mountPath: /etc/triliovault_wlm/certs/ca.crt
              subPath: ca.crt
              readOnly: true            
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/ca.crt
              subPath: ca.crt
              readOnly: true

      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: vartrilio
          hostPath:
            path: /var/trilio
        - name: triliovault-wlm-etc
          secret:
            secretName: triliovault-wlm-etc
            defaultMode: 0444
        - name: triliovault-wlm-bin
          configMap:
            name: triliovault-wlm-bin
            defaultMode: 0555
        - name: triliovault-nfs-pv--
          persistentVolumeClaim:
            claimName: triliovault-nfs-pvc--
	      - name: pod-shared-triliovault-wlm-workloads
          emptyDir: {}        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292        
        - name: triliovault-wlm-tls-api
          secret:
            secretName: triliovault-wlm-tls-api
            defaultMode: 292        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292


---
# Source: triliovault/templates/job-datamover-db-init.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-datamover-db-init
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-datamover-db-init
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-datamover-db-init
subjects:
  - kind: ServiceAccount
    name: triliovault-datamover-db-init
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-datamover-db-init
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-datamover-db-init"
  labels:
    release_group: release-name
    application: triliovault-datamover
    component: db-init
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-5"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-datamover
        component: db-init
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-datamover-db-init
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: ""
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:

        - name: "triliovault-datamover-db-init-0"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          env:
            - name: ROOT_DB_CONNECTION
              valueFrom:
                secretKeyRef:
                  name: "triliovault-db-admin"
                  key: DB_CONNECTION
            - name: OPENSTACK_CONFIG_FILE
              value: "/etc/triliovault-datamover/triliovault-datamover-api.conf"
            - name: OPENSTACK_CONFIG_DB_SECTION
              value: "database"
            - name: OPENSTACK_CONFIG_DB_KEY
              value: "connection"
            - name: MARIADB_X509
              value: "REQUIRE X509"
          command:
            - /tmp/db-init.py
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: db-init-sh
              mountPath: /tmp/db-init.py
              subPath: db-init.py
              readOnly: true
            - name: etc-service
              mountPath: "/etc/triliovault-datamover"
            - name: db-init-conf
              mountPath: "/etc/triliovault-datamover/triliovault-datamover-api.conf"
              subPath: "triliovault-datamover-api.conf"
              readOnly: true
            - name: db-init-conf
              mountPath: "/etc/triliovault-datamover/logging.conf"
              subPath: "logging.conf"
              readOnly: true            
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/ca.crt
              subPath: ca.crt
              readOnly: true
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: db-init-sh
          configMap:
            name: "triliovault-datamover-bin"
            defaultMode: 0555        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292
        - name: etc-service
          emptyDir: {}
        - name: db-init-conf
          secret:
            secretName: "triliovault-datamover-etc"
            defaultMode: 0444



---
# Source: triliovault/templates/job-datamover-db-sync.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-datamover-db-sync
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-datamover-db-sync
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-datamover-db-sync
subjects:
  - kind: ServiceAccount
    name: triliovault-datamover-db-sync
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-datamover-db-sync
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-datamover-db-sync"
  labels:
    release_group: release-name
    application: triliovault_datamover
    component: db-sync
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-4"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault_datamover
        component: db-sync
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-datamover-db-sync
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: ""
            - name: DEPENDENCY_JOBS
              value: "tvault-db-init"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: "triliovault-datamover-db-sync"
          image: 
          imagePullPolicy: "IfNotPresent"
          
          command:
            - /bin/bash
            - -c
            - /tmp/db-sync.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: db-sync-sh
              mountPath: /tmp/db-sync.sh
              subPath: db-sync.sh
              readOnly: true
            - name: etc-service
              mountPath: "/etc/triliovault-datamover"
            - name: db-sync-conf
              mountPath: "/etc/triliovault-datamover/triliovault-datamover.conf"
              subPath: "triliovault-datamover.conf"
              readOnly: true
            - name: db-sync-conf
              mountPath: "/etc/triliovault-datamover/logging.conf"
              subPath: "logging.conf"
              readOnly: true            
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: db-sync-sh
          configMap:
            name: "triliovault_datamover-bin"
            defaultMode: 0555
        - name: etc-service
          emptyDir: {}
        - name: db-sync-conf
          secret:
            secretName: "triliovault_datamover-etc"
            defaultMode: 0444        




---
# Source: triliovault/templates/job-datamover-ks-endpoints.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-ks-endpoints
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-ks-endpoints
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-ks-endpoints
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-ks-endpoints
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-ks-endpoints
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-wlm-ks-endpoints"
  labels:
    release_group: release-name
    application: triliovault-wlm
    component: ks-endpoints
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-2"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-wlm
        component: ks-endpoints
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-wlm-ks-endpoints
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:keystone-api"
            - name: DEPENDENCY_JOBS
              value: "triliovault-ks-service"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: "datamover-ks-endpoints-admin"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
            
            - name: triliovault-datamover-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SVC_ENDPOINT
              value: "admin"
            - name: OS_SERVICE_NAME
              value: "dmapi"
            - name: OS_SERVICE_TYPE
              value: "datamover"
            - name: OS_SERVICE_ENDPOINT
              value: "https://triliovault-datamover-api.default.svc.cluster.local:8784/v2"
        - name: "datamover-ks-endpoints-internal"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
            
            - name: triliovault-datamover-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SVC_ENDPOINT
              value: "internal"
            - name: OS_SERVICE_NAME
              value: "dmapi"
            - name: OS_SERVICE_TYPE
              value: "datamover"
            - name: OS_SERVICE_ENDPOINT
              value: "https://triliovault-datamover-api.default.svc.cluster.local:8784/v2"
        - name: "datamover-ks-endpoints-public"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
            
            - name: triliovault-datamover-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SVC_ENDPOINT
              value: "public"
            - name: OS_SERVICE_NAME
              value: "dmapi"
            - name: OS_SERVICE_TYPE
              value: "datamover"
            - name: OS_SERVICE_ENDPOINT
              value: "https://triliovault-datamover.default.svc.cluster.local/v2"
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-endpoints-sh
          configMap:
            name: "triliovault-wlm-bin"
            defaultMode: 0555        
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292

---
# Source: triliovault/templates/job-datamover-ks-service.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-datamover-ks-service
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-datamover-ks-service
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-datamover-ks-service
subjects:
  - kind: ServiceAccount
    name: triliovault-datamover-ks-service
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-datamover-ks-service
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-datamover-ks-service"
  labels:
    release_group: release-name
    application: triliovault-datamover
    component: ks-service
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-3"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-datamover
        component: ks-service
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-datamover-ks-service
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:keystone-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: "datamover-ks-service-registration"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-service.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-service-sh
              mountPath: /tmp/ks-service.sh
              subPath: ks-service.sh
              readOnly: true
            
            - name: triliovault-datamover-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SERVICE_NAME
              value: "dmapi"
            - name: OS_SERVICE_TYPE
              value: "datamover"
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-service-sh
          configMap:
            name: "triliovault-datamover-bin"
            defaultMode: 0555        
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292


---
# Source: triliovault/templates/job-datamover-ks-user.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-datamover-ks-user
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-datamover-ks-user
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-datamover-ks-user
subjects:
  - kind: ServiceAccount
    name: triliovault-datamover-ks-user
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-datamover-ks-user
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-datamover-ks-user"
  labels:
    release_group: release-name
    application: triliovault_datamover
    component: ks-user
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-1"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault_datamover
        component: ks-user
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: "triliovault-datamover-ks-user"
      securityContext:
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:keystone-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: ks-user
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-user.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-user-sh
              mountPath: /tmp/ks-user.sh
              subPath: ks-user.sh
              readOnly: true
            
            - name: triliovault-datamover-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: SERVICE_OS_SERVICE_NAME
              value: "triliovault_datamover"            
            - name: SERVICE_OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-datamover-keystone-user
                  key: OS_REGION_NAME
            - name: SERVICE_OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-datamover-keystone-user
                  key: OS_PROJECT_DOMAIN_NAME
            - name: SERVICE_OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-datamover-keystone-user
                  key: OS_PROJECT_NAME
            - name: SERVICE_OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-datamover-keystone-user
                  key: OS_USER_DOMAIN_NAME
            - name: SERVICE_OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-datamover-keystone-user
                  key: OS_USERNAME
            - name: SERVICE_OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-datamover-keystone-user
                  key: OS_PASSWORD
            - name: SERVICE_OS_ROLES
              value: "admin"
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-user-sh
          configMap:
            name: "triliovault_datamover-bin"
            defaultMode: 0555        
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292

---
# Source: triliovault/templates/job-wlm-db-init.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-datamover-db-init
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-datamover-db-init
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-datamover-db-init
subjects:
  - kind: ServiceAccount
    name: triliovault-datamover-db-init
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-datamover-db-init
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-datamover-db-init"
  labels:
    release_group: release-name
    application: triliovault-datamover
    component: db-init
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-5"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-datamover
        component: db-init
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-datamover-db-init
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: ""
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:

        - name: "triliovault-datamover-db-init-0"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          env:
            - name: ROOT_DB_CONNECTION
              valueFrom:
                secretKeyRef:
                  name: "triliovault-db-admin"
                  key: DB_CONNECTION
            - name: OPENSTACK_CONFIG_FILE
              value: "/etc/triliovault-datamover/triliovault-wlm-api.conf"
            - name: OPENSTACK_CONFIG_DB_SECTION
              value: "database"
            - name: OPENSTACK_CONFIG_DB_KEY
              value: "connection"
            - name: MARIADB_X509
              value: "REQUIRE X509"
          command:
            - /tmp/db-init.py
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: db-init-sh
              mountPath: /tmp/db-init.py
              subPath: db-init.py
              readOnly: true
            - name: etc-service
              mountPath: "/etc/triliovault-datamover"
            - name: db-init-conf
              mountPath: "/etc/triliovault-datamover/triliovault-wlm-api.conf"
              subPath: "triliovault-wlm-api.conf"
              readOnly: true
            - name: db-init-conf
              mountPath: "/etc/triliovault-datamover/logging.conf"
              subPath: "logging.conf"
              readOnly: true            
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: mariadb-tls-direct
              mountPath: /etc/mysql/certs/ca.crt
              subPath: ca.crt
              readOnly: true
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: db-init-sh
          configMap:
            name: "triliovault-datamover-bin"
            defaultMode: 0555        
        - name: mariadb-tls-direct
          secret:
            secretName: mariadb-tls-direct
            defaultMode: 292
        - name: etc-service
          emptyDir: {}
        - name: db-init-conf
          secret:
            secretName: "triliovault-datamover-etc"
            defaultMode: 0444

---
# Source: triliovault/templates/job-wlm-db-sync.yaml


---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-db-sync
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-db-sync
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-db-sync
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-db-sync
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-db-sync
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-wlm-db-sync"
  labels:
    release_group: release-name
    application: triliovault_wlm
    component: db-sync
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-4"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault_wlm
        component: db-sync
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-wlm-db-sync
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: ""
            - name: DEPENDENCY_JOBS
              value: "tvault-db-init"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: "triliovault-wlm-db-sync"
          image: 
          imagePullPolicy: "IfNotPresent"
          
          command:
            - /bin/bash
            - -c
            - /tmp/db-sync.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: db-sync-sh
              mountPath: /tmp/db-sync.sh
              subPath: db-sync.sh
              readOnly: true
            - name: etc-service
              mountPath: "/etc/triliovault-wlm"
            - name: db-sync-conf
              mountPath: "/etc/triliovault-wlm/triliovault-wlm.conf"
              subPath: "triliovault-wlm.conf"
              readOnly: true
            - name: db-sync-conf
              mountPath: "/etc/triliovault-wlm/logging.conf"
              subPath: "logging.conf"
              readOnly: true            
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: db-sync-sh
          configMap:
            name: "triliovault_wlm-bin"
            defaultMode: 0555
        - name: etc-service
          emptyDir: {}
        - name: db-sync-conf
          secret:
            secretName: "triliovault_wlm-etc"
            defaultMode: 0444        

---
# Source: triliovault/templates/job-wlm-ks-endpoints.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-ks-endpoints
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-ks-endpoints
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-ks-endpoints
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-ks-endpoints
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-ks-endpoints
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
      - jobs
      - pods
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-wlm-ks-endpoints"
  labels:
    release_group: release-name
    application: triliovault-wlm
    component: ks-endpoints
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-2"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-wlm
        component: ks-endpoints
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-wlm-ks-endpoints
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:keystone-api"
            - name: DEPENDENCY_JOBS
              value: "triliovault-ks-service"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: "workloads-ks-endpoints-admin"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
            
            - name: triliovault-wlm-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SVC_ENDPOINT
              value: "admin"
            - name: OS_SERVICE_NAME
              value: "workloadmgr"
            - name: OS_SERVICE_TYPE
              value: "workloads"
            - name: OS_SERVICE_ENDPOINT
              value: "https://triliovault-wlm-api.default.svc.cluster.local:8780/v1/$(tenant_id)s"
        - name: "workloads-ks-endpoints-internal"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
            
            - name: triliovault-wlm-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SVC_ENDPOINT
              value: "internal"
            - name: OS_SERVICE_NAME
              value: "workloadmgr"
            - name: OS_SERVICE_TYPE
              value: "workloads"
            - name: OS_SERVICE_ENDPOINT
              value: "https://triliovault-wlm-api.default.svc.cluster.local:8780/v1/$(tenant_id)s"
        - name: "workloads-ks-endpoints-public"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-endpoints.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-endpoints-sh
              mountPath: /tmp/ks-endpoints.sh
              subPath: ks-endpoints.sh
              readOnly: true
            
            - name: triliovault-wlm-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SVC_ENDPOINT
              value: "public"
            - name: OS_SERVICE_NAME
              value: "workloadmgr"
            - name: OS_SERVICE_TYPE
              value: "workloads"
            - name: OS_SERVICE_ENDPOINT
              value: "https://triliovault-wlm.default.svc.cluster.local/v1/$(tenant_id)s"
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-endpoints-sh
          configMap:
            name: "triliovault-wlm-bin"
            defaultMode: 0555        
        - name: triliovault-wlm-tls-api
          secret:
            secretName: triliovault-wlm-tls-api
            defaultMode: 292

---
# Source: triliovault/templates/job-wlm-ks-service.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-ks-service
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-ks-service
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-ks-service
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-ks-service
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-ks-service
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-wlm-ks-service"
  labels:
    release_group: release-name
    application: triliovault-wlm
    component: ks-service
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-3"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-wlm
        component: ks-service
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-wlm-ks-service
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:keystone-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: "workloads-ks-service-registration"
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-service.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-service-sh
              mountPath: /tmp/ks-service.sh
              subPath: ks-service.sh
              readOnly: true
            
            - name: triliovault-wlm-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: OS_SERVICE_NAME
              value: "workloadmgr"
            - name: OS_SERVICE_TYPE
              value: "workloads"
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-service-sh
          configMap:
            name: "triliovault-wlm-bin"
            defaultMode: 0555        
        - name: triliovault-wlm-tls-api
          secret:
            secretName: triliovault-wlm-tls-api
            defaultMode: 292

---
# Source: triliovault/templates/job-wlm-ks-user.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-ks-user
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-ks-user
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-ks-user
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-ks-user
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-ks-user
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-wlm-ks-user"
  labels:
    release_group: release-name
    application: triliovault_wlm
    component: ks-user
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-1"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault_wlm
        component: ks-user
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: "triliovault-wlm-ks-user"
      securityContext:
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:keystone-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: ks-user
          image: docker.io/openstackhelm/heat:ocata-ubuntu_xenial
          imagePullPolicy: IfNotPresent
          
          
          command:
            - /bin/bash
            - -c
            - /tmp/ks-user.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: ks-user-sh
              mountPath: /tmp/ks-user.sh
              subPath: ks-user.sh
              readOnly: true
            
            - name: triliovault-wlm-tls-api
              mountPath: "/etc/ssl/certs/openstack-helm.crt"
              subPath: ca.crt
              readOnly: true
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
            - name: OS_CACERT
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_CACERT
            - name: SERVICE_OS_SERVICE_NAME
              value: "triliovault_wlm"            
            - name: SERVICE_OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-wlm-keystone-user
                  key: OS_REGION_NAME
            - name: SERVICE_OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-wlm-keystone-user
                  key: OS_PROJECT_DOMAIN_NAME
            - name: SERVICE_OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-wlm-keystone-user
                  key: OS_PROJECT_NAME
            - name: SERVICE_OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-wlm-keystone-user
                  key: OS_USER_DOMAIN_NAME
            - name: SERVICE_OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-wlm-keystone-user
                  key: OS_USERNAME
            - name: SERVICE_OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-wlm-keystone-user
                  key: OS_PASSWORD
            - name: SERVICE_OS_ROLES
              value: "admin"
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: ks-user-sh
          configMap:
            name: "triliovault_wlm-bin"
            defaultMode: 0555        
        - name: triliovault-wlm-tls-api
          secret:
            secretName: triliovault-wlm-tls-api
            defaultMode: 292


---
# Source: triliovault/templates/job-wlm-rabbit-init.yaml



---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: triliovault-wlm-rabbit-init
  namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-triliovault-wlm-rabbit-init
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-default-triliovault-wlm-rabbit-init
subjects:
  - kind: ServiceAccount
    name: triliovault-wlm-rabbit-init
    namespace: default
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-default-triliovault-wlm-rabbit-init
  namespace: default
rules:
  - apiGroups:
      - ""
      - extensions
      - batch
      - apps
    verbs:
      - get
      - list
    resources:
      - services
      - endpoints
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-wlm-rabbit-init"
  labels:
    release_group: release-name
    application: triliovault-wlm
    component: rabbit-init
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-weight: "-4"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-wlm
        component: rabbit-init
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: "triliovault-wlm-rabbit-init"
      restartPolicy: OnFailure
            
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:rabbitmq"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
      containers:
        - name: rabbit-init
          image: "docker.io/rabbitmq:3.7-management"
          imagePullPolicy: "IfNotPresent"
          
          command:
            - /bin/bash
            - -c
            - /tmp/rabbit-init.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: rabbit-init-sh
              mountPath: /tmp/rabbit-init.sh
              subPath: rabbit-init.sh
              readOnly: true            
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.crt
              subPath: tls.crt
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/tls.key
              subPath: tls.key
              readOnly: true
            - name: rabbitmq-tls-direct
              mountPath: /etc/rabbitmq/certs/ca.crt
              subPath: ca.crt
              readOnly: true
          env:
          - name: RABBITMQ_ADMIN_CONNECTION
            valueFrom:
              secretKeyRef:
                name: triliovault-rabbitmq-admin
                key: RABBITMQ_CONNECTION
          - name: RABBITMQ_USER_CONNECTION
            valueFrom:
              secretKeyRef:
                name: 
                key: RABBITMQ_CONNECTION
          - name: RABBITMQ_X509
            value: "REQUIRE X509"
          - name: USER_CERT_PATH
            value: "/etc/rabbitmq/certs"
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: rabbit-init-sh
          configMap:
            name: "triliovault-wlm-bin"
            defaultMode: 0555        
        - name: rabbitmq-tls-direct
          secret:
            secretName: rabbitmq-tls-direct
            defaultMode: 292


---
# Source: triliovault/templates/service-datamover-api.yaml

---
apiVersion: v1
kind: Service
metadata:
  name: triliovault-datamover-api
spec:
  ports:
    - name: d-api
      port: 8784
      
  selector:
    release_group: release-name
    application: triliovault
    component: datamover-api
  

---
# Source: triliovault/templates/service-ingress-datamover-api.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: triliovault-datamover
spec:
  ports:
    - name: http
      port: 80
    - name: https
      port: 443
  selector:
    app: ingress-api

---
# Source: triliovault/templates/service-ingress-wlm-api.yaml
---
apiVersion: v1
kind: Service
metadata:
  name: triliovault-wlm
spec:
  ports:
    - name: http
      port: 80
    - name: https
      port: 443
  selector:
    app: ingress-api

---
# Source: triliovault/templates/service-wlm-api.yaml

---
apiVersion: v1
kind: Service
metadata:
  name: triliovault-wlm-api
spec:
  ports:
    - name: w-api
      port: 8780
      
  selector:
    release_group: release-name
    application: triliovault
    component: wlm-api
  

---
# Source: triliovault/templates/job-wlm-cloud-trust.yaml


---
apiVersion: batch/v1
kind: Job
metadata:
  name: "triliovault-wlm-cloud-trust"
  labels:
    release_group: release-name
    application: triliovault-wlm
    component: cloud-trust
  annotations:
    |2-
    
      helm.sh/hook: post-install,post-upgrade
      helm.sh/hook-weight: "-1"
    
spec:
  backoffLimit: 1000
  template:
    metadata:
      labels:
        release_group: release-name
        application: triliovault-datamover
        component: ks-service
      annotations:
        "openstackhelm.openstack.org/release_uuid": ""
    spec:
      serviceAccountName: triliovault-datamover-ks-service
      restartPolicy: OnFailure
      nodeSelector:
        openstack-control-plane: enabled
        
      initContainers:
        
        - name: init
          image: "quay.io/airshipit/kubernetes-entrypoint:v1.0.0"
          imagePullPolicy: IfNotPresent  
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsUser: 65534
            
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.namespace
            - name: INTERFACE_NAME
              value: eth0
            - name: PATH
              value: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/
            - name: DEPENDENCY_SERVICE
              value: "default:keystone-api"
            - name: DEPENDENCY_DAEMONSET
              value: ""
            - name: DEPENDENCY_CONTAINER
              value: ""
            - name: DEPENDENCY_POD_JSON
              value: ""
            - name: DEPENDENCY_CUSTOM_RESOURCE
              value: ""
          command:
            - kubernetes-entrypoint
          volumeMounts:
            []
            
     containers:
        - name: "wlm-cloud-trust-creation"
          image: docker.io/trilio/triliovault-wlm-helm:5.0.0-train-ubuntu_bionic
          imagePullPolicy: IfNotPresent
          command:
            - /bin/bash
            - -c
            - /tmp/triliovault-wlm-cloud-trust.sh
          volumeMounts:
            - name: pod-tmp
              mountPath: /tmp
            - name: wlm-cloud-trust-sh
              mountPath: /tmp/triliovault-wlm-cloud-trust.sh
              subPath: triliovault-wlm-cloud-trust.sh
              readOnly: true
            
          env:            
            - name: OS_IDENTITY_API_VERSION
              value: "3"
            - name: OS_AUTH_URL
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_AUTH_URL
            - name: OS_REGION_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_REGION_NAME
            - name: OS_INTERFACE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_ENDPOINT_TYPE
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_INTERFACE
            - name: OS_PROJECT_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_DOMAIN_NAME
            - name: OS_PROJECT_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PROJECT_NAME
            - name: OS_USER_DOMAIN_NAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USER_DOMAIN_NAME
            - name: OS_USERNAME
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_USERNAME
            - name: OS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_PASSWORD
            - name: OS_DEFAULT_DOMAIN
              valueFrom:
                secretKeyRef:
                  name: triliovault-keystone-admin
                  key: OS_DEFAULT_DOMAIN
      volumes:
        - name: pod-tmp
          emptyDir: {}
        - name: triliovault-wlm-cloud-trust-sh
          configMap:
            name: "triliovault-datamover-bin"
            defaultMode: 0555
        - name: triliovault-datamover-tls-api
          secret:
            secretName: triliovault-datamover-tls-api
            defaultMode: 292        

---
# Source: triliovault/templates/ingress-datamover-api.yaml

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: triliovault-datamover
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: ca-issuer
    certmanager.k8s.io/cluster-issuer: ca-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /
    
spec:
  tls:
    - secretName: triliovault-datamover-tls-public-ing
      hosts:
        - triliovault-datamover
        - triliovault-datamover.default
        - triliovault-datamover.default.svc.cluster.local
  rules:
    - host: triliovault-datamover
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: triliovault-datamover-api
                port:
                  name: "d-api"
    - host: triliovault-datamover.default
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: triliovault-datamover-api
                port:
                  name: "d-api"
    - host: triliovault-datamover.default.svc.cluster.local
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: triliovault-datamover-api
                port:
                  name: "d-api"


---
# Source: triliovault/templates/ingress-wlm-api.yaml

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: triliovault-wlm
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: ca-issuer
    certmanager.k8s.io/cluster-issuer: ca-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /
    
spec:
  tls:
    - secretName: triliovault-wlm-tls-public-ing
      hosts:
        - triliovault-wlm
        - triliovault-wlm.default
        - triliovault-wlm.default.svc.cluster.local
  rules:
    - host: triliovault-wlm
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: triliovault-wlm-api
                port:
                  name: "w-api"
    - host: triliovault-wlm.default
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: triliovault-wlm-api
                port:
                  name: "w-api"
    - host: triliovault-wlm.default.svc.cluster.local
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: triliovault-wlm-api
                port:
                  name: "w-api"


---
# Source: triliovault/templates/job-datamover-bootstrap.yaml

---
# Source: triliovault/templates/job-datamover-db-drop.yaml


---
# Source: triliovault/templates/job-image-repo-sync.yaml





---
# Source: triliovault/templates/job-wlm-bootstrap.yaml


---
# Source: triliovault/templates/job-wlm-db-drop.yaml

---
# Source: triliovault/templates/network_policy_datamover.yaml

---
# Source: triliovault/templates/network_policy_wlm.yaml

---
# Source: triliovault/templates/secret-datamover-ingress-tls.yaml


---
# Source: triliovault/templates/secret-wlm-ingress-tls.yaml


